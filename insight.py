"""
Data Science Workflow Studio Pro - ä¸Šç´šè€…å¯¾å¿œç‰ˆ
å®Ÿå‹™ç‰¹åŒ–å‹ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¢ãƒ—ãƒª + çµ±è¨ˆçš„å³å¯†æ€§ + ã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ©Ÿèƒ½ + ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
pip install streamlit pandas numpy scipy scikit-learn plotly statsmodels

å®Ÿè¡Œ:
streamlit run app.py
"""

import streamlit as st
import pandas as pd
import numpy as np
from io import StringIO
from scipy import stats
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_validate, KFold, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, mean_absolute_error
from sklearn.inspection import permutation_importance
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor, OLSInfluence
from statsmodels.stats.diagnostic import het_breuschpagan, linear_rainbow
from statsmodels.stats.stattools import durbin_watson, jarque_bera
from datetime import datetime
import warnings
import json
warnings.filterwarnings('ignore')

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Data Science Workflow Studio Pro",
    layout="wide",
    initial_sidebar_state='expanded'
)

# ã‚¹ã‚¿ã‚¤ãƒ«
st.markdown("""
<style>
    [data-testid='stAppViewContainer'] {
        background: linear-gradient(135deg, #0f172a 0%, #1f2937 100%);
    }
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #ffffff;
        text-align: center;
        padding: 1rem;
        background: linear-gradient(90deg, #8b5cf6, #ec4899);
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .step-header {
        font-size: 1.8rem;
        font-weight: bold;
        color: #8b5cf6;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .info-box {
        background-color: #1e293b;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 5px solid #8b5cf6;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #064e3b;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #10b981;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #7c2d12;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #f59e0b;
        margin: 1rem 0;
    }
    .diagnostic-pass {
        background-color: #064e3b;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.5rem 0;
    }
    .diagnostic-fail {
        background-color: #7c2d12;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.5rem 0;
    }
    .impact-positive {
        background: linear-gradient(90deg, #064e3b, #10b981);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
    }
    .impact-negative {
        background: linear-gradient(90deg, #7c2d12, #f59e0b);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
if 'step' not in st.session_state:
    st.session_state.step = 1
if 'df' not in st.session_state:
    st.session_state.df = None
if 'processed_df' not in st.session_state:
    st.session_state.processed_df = None
if 'column_mapping' not in st.session_state:
    st.session_state.column_mapping = {}
if 'selected_target' not in st.session_state:
    st.session_state.selected_target = None
if 'selected_features' not in st.session_state:
    st.session_state.selected_features = []
if 'model_results' not in st.session_state:
    st.session_state.model_results = {}
if 'diagnostics_results' not in st.session_state:
    st.session_state.diagnostics_results = None
if 'best_model' not in st.session_state:
    st.session_state.best_model = None
if 'current_model' not in st.session_state:
    st.session_state.current_model = None
if 'current_X_test' not in st.session_state:
    st.session_state.current_X_test = None
if 'current_y_test' not in st.session_state:
    st.session_state.current_y_test = None
if 'current_y_pred' not in st.session_state:
    st.session_state.current_y_pred = None

# ==================== çµ±è¨ˆçš„å³å¯†æ€§ã®ãŸã‚ã®é–¢æ•° ====================

def comprehensive_regression_diagnostics(model_sm, X, y, residuals):
    """å›å¸°åˆ†æã®å®Œå…¨ãªè¨ºæ–­"""
    diagnostics = {}
    
    try:
        rainbow_stat, rainbow_p = linear_rainbow(model_sm)
        diagnostics['linearity'] = {
            'test': 'Rainbow Test',
            'statistic': float(rainbow_stat),
            'p_value': float(rainbow_p),
            'passed': rainbow_p > 0.05,
            'interpretation': 'ç·šå½¢é–¢ä¿‚ãŒé©åˆ‡' if rainbow_p > 0.05 else 'éç·šå½¢æ€§ã®å¯èƒ½æ€§ã‚ã‚Š'
        }
    except:
        diagnostics['linearity'] = {
            'test': 'Rainbow Test',
            'statistic': None,
            'p_value': None,
            'passed': None,
            'interpretation': 'è¨ˆç®—ä¸å¯'
        }
    
    try:
        X_with_const = sm.add_constant(X)
        bp_stat, bp_p, _, _ = het_breuschpagan(residuals, X_with_const)
        diagnostics['homoscedasticity'] = {
            'test': 'Breusch-Pagan Test',
            'statistic': float(bp_stat),
            'p_value': float(bp_p),
            'passed': bp_p > 0.05,
            'interpretation': 'ç­‰åˆ†æ•£æ€§ã‚ã‚Š' if bp_p > 0.05 else 'ä¸ç­‰åˆ†æ•£ï¼ˆWLSå›å¸°ã‚’æ¤œè¨ï¼‰',
            'remedy': '' if bp_p > 0.05 else 'ãƒ­ãƒã‚¹ãƒˆæ¨™æº–èª¤å·®ã®ä½¿ç”¨ã€ã¾ãŸã¯WLSï¼ˆåŠ é‡æœ€å°äºŒä¹—æ³•ï¼‰ã¸ã®å¤‰æ›´ã‚’æ¨å¥¨'
        }
    except:
        diagnostics['homoscedasticity'] = {
            'test': 'Breusch-Pagan Test',
            'statistic': None,
            'p_value': None,
            'passed': None,
            'interpretation': 'è¨ˆç®—ä¸å¯'
        }
    
    try:
        jb_stat, jb_p, skew, kurtosis = jarque_bera(residuals)
        diagnostics['normality'] = {
            'test': 'Jarque-Bera Test',
            'statistic': float(jb_stat),
            'p_value': float(jb_p),
            'skewness': float(skew),
            'kurtosis': float(kurtosis),
            'passed': jb_p > 0.05,
            'interpretation': 'æ­£è¦åˆ†å¸ƒã«å¾“ã†' if jb_p > 0.05 else 'æ­£è¦æ€§é•å',
            'remedy': '' if jb_p > 0.05 else 'ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒååˆ†å¤§ãã‘ã‚Œã°å•é¡Œãªã—ï¼ˆä¸­å¿ƒæ¥µé™å®šç†ï¼‰'
        }
    except:
        diagnostics['normality'] = {
            'test': 'Jarque-Bera Test',
            'statistic': None,
            'p_value': None,
            'passed': None,
            'interpretation': 'è¨ˆç®—ä¸å¯'
        }
    
    try:
        dw_stat = durbin_watson(residuals)
        diagnostics['autocorrelation'] = {
            'test': 'Durbin-Watson Test',
            'statistic': float(dw_stat),
            'passed': 1.5 < dw_stat < 2.5,
            'interpretation': 'è‡ªå·±ç›¸é–¢ãªã—' if 1.5 < dw_stat < 2.5 else f'è‡ªå·±ç›¸é–¢ã®å¯èƒ½æ€§',
            'remedy': '' if 1.5 < dw_stat < 2.5 else 'æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ARIMAãƒ¢ãƒ‡ãƒ«ã‚’æ¤œè¨'
        }
    except:
        diagnostics['autocorrelation'] = {
            'test': 'Durbin-Watson Test',
            'statistic': None,
            'passed': None,
            'interpretation': 'è¨ˆç®—ä¸å¯'
        }
    
    try:
        vif_data = pd.DataFrame()
        vif_data["feature"] = X.columns
        vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]
        
        diagnostics['multicollinearity'] = {
            'test': 'Variance Inflation Factor (VIF)',
            'data': vif_data,
            'passed': (vif_data['VIF'] < 10).all(),
            'severe': (vif_data['VIF'] > 10).any(),
            'max_vif': float(vif_data['VIF'].max()),
            'interpretation': 'å¤šé‡å…±ç·šæ€§ãªã—ï¼ˆVIF<10ï¼‰' if (vif_data['VIF'] < 10).all() else f'å¤šé‡å…±ç·šæ€§ã‚ã‚Š',
            'remedy': '' if (vif_data['VIF'] < 10).all() else 'Ridgeå›å¸°ã€Lassoå›å¸°ã‚’æ¤œè¨'
        }
    except:
        diagnostics['multicollinearity'] = {
            'test': 'VIF',
            'passed': None,
            'interpretation': 'è¨ˆç®—ä¸å¯'
        }
    
    try:
        influence = OLSInfluence(model_sm)
        cooks_d = influence.cooks_distance[0]
        cooks_threshold = 4 / len(residuals)
        high_influence = np.where(cooks_d > cooks_threshold)[0]
        
        diagnostics['influence'] = {
            'test': "Cook's Distance",
            'threshold': float(cooks_threshold),
            'n_influential': int(len(high_influence)),
            'influential_indices': high_influence.tolist()[:10],
            'passed': len(high_influence) < len(residuals) * 0.05,
            'interpretation': f'{len(high_influence)}å€‹ã®å½±éŸ¿åŠ›ã®å¤§ãã„è¦³æ¸¬å€¤',
            'remedy': '' if len(high_influence) == 0 else 'å½±éŸ¿åŠ›ã®å¤§ãã„è¦³æ¸¬å€¤ã‚’è©³ç´°èª¿æŸ»'
        }
    except:
        diagnostics['influence'] = {
            'test': "Cook's Distance",
            'passed': None,
            'interpretation': 'è¨ˆç®—ä¸å¯'
        }
    
    return diagnostics


def calculate_effect_sizes(model_sm, X, y):
    """åŠ¹æœé‡ã‚’è¨ˆç®—"""
    effect_sizes = {}
    
    try:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)
        X_scaled_with_const = sm.add_constant(X_scaled_df)
        model_scaled = sm.OLS(y, X_scaled_with_const).fit()
        
        effect_sizes['standardized_coefficients'] = pd.DataFrame({
            'feature': X.columns,
            'beta': model_scaled.params[1:].values,
            'abs_beta': np.abs(model_scaled.params[1:].values)
        }).sort_values('abs_beta', ascending=False)
    except:
        effect_sizes['standardized_coefficients'] = None
    
    try:
        full_r2 = model_sm.rsquared
        partial_r2_list = []
        for col in X.columns:
            X_reduced = X.drop(columns=[col])
            X_reduced_with_const = sm.add_constant(X_reduced)
            model_reduced = sm.OLS(y, X_reduced_with_const).fit()
            reduced_r2 = model_reduced.rsquared
            partial_r2_list.append(full_r2 - reduced_r2)
        
        effect_sizes['partial_r2'] = pd.DataFrame({
            'feature': X.columns,
            'partial_r2': partial_r2_list,
            'percentage': np.array(partial_r2_list) / full_r2 * 100 if full_r2 > 0 else 0
        }).sort_values('partial_r2', ascending=False)
    except:
        effect_sizes['partial_r2'] = None
    
    try:
        full_r2 = model_sm.rsquared
        if full_r2 < 1:
            cohens_f2 = full_r2 / (1 - full_r2)
        else:
            cohens_f2 = np.inf
        
        if cohens_f2 < 0.02:
            interpretation = "å°ã•ã„åŠ¹æœ"
        elif cohens_f2 < 0.15:
            interpretation = "ä¸­ç¨‹åº¦ã®åŠ¹æœ"
        elif cohens_f2 < 0.35:
            interpretation = "å¤§ãã„åŠ¹æœ"
        else:
            interpretation = "éå¸¸ã«å¤§ãã„åŠ¹æœ"
        
        effect_sizes['cohens_f2'] = {
            'value': float(cohens_f2),
            'interpretation': interpretation
        }
    except:
        effect_sizes['cohens_f2'] = None
    
    return effect_sizes


def rigorous_cross_validation(model, X, y, cv=5):
    """å³å¯†ãªã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
    try:
        scoring = {
            'r2': 'r2',
            'neg_mse': 'neg_mean_squared_error',
            'neg_mae': 'neg_mean_absolute_error'
        }
        
        cv_results = cross_validate(
            model, X, y,
            cv=KFold(n_splits=cv, shuffle=True, random_state=42),
            scoring=scoring,
            return_train_score=True,
            n_jobs=-1
        )
        
        train_r2 = cv_results['train_r2'].mean()
        test_r2 = cv_results['test_r2'].mean()
        overfit_gap = train_r2 - test_r2
        
        results = {
            'test_r2_mean': float(test_r2),
            'test_r2_std': float(cv_results['test_r2'].std()),
            'train_r2_mean': float(train_r2),
            'test_mse_mean': float(-cv_results['neg_mse'].mean()),
            'test_mae_mean': float(-cv_results['neg_mae'].mean()),
            'overfit_gap': float(overfit_gap),
            'is_overfitting': overfit_gap > 0.1,
            'cv_scores': cv_results
        }
        
        return results
    except Exception as e:
        st.error(f"ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def display_diagnostics_report(diagnostics):
    """è¨ºæ–­çµæœã‚’è¡¨ç¤º"""
    st.markdown("---")
    st.markdown("### ğŸ“‹ çµ±è¨ˆçš„è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ")
    
    passed_tests = [d.get('passed') for d in diagnostics.values() if d.get('passed') is not None]
    
    if passed_tests:
        all_passed = all(passed_tests)
        pass_rate = sum(passed_tests) / len(passed_tests) * 100
        
        col_summary1, col_summary2 = st.columns(2)
        with col_summary1:
            if all_passed:
                st.markdown('<div class="diagnostic-pass">âœ… ã™ã¹ã¦ã®å‰ææ¡ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã™</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="diagnostic-fail">âš ï¸ ä¸€éƒ¨ã®å‰ææ¡ä»¶ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ï¼ˆåˆæ ¼ç‡: {pass_rate:.0f}%ï¼‰</div>', unsafe_allow_html=True)
        
        with col_summary2:
            st.info("çµæœã®è§£é‡ˆã«æ³¨æ„ãŒå¿…è¦ã§ã™")
    
    for test_name, result in diagnostics.items():
        with st.expander(f"{'âœ…' if result.get('passed') else 'âŒ'} {test_name.upper()} - {result['test']}"):
            
            if result.get('statistic') is not None:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("æ¤œå®šçµ±è¨ˆé‡", f"{result['statistic']:.4f}")
                    if 'p_value' in result and result['p_value'] is not None:
                        st.metric("på€¤", f"{result['p_value']:.4f}")
                    
                    if test_name == 'normality' and 'skewness' in result:
                        st.metric("æ­ªåº¦", f"{result['skewness']:.4f}")
                        st.metric("å°–åº¦", f"{result['kurtosis']:.4f}")
                    
                    if test_name == 'multicollinearity' and 'max_vif' in result:
                        st.metric("æœ€å¤§VIF", f"{result['max_vif']:.2f}")
                    
                    if test_name == 'influence' and 'n_influential' in result:
                        st.metric("å½±éŸ¿åŠ›ã®å¤§ãã„è¦³æ¸¬å€¤æ•°", result['n_influential'])
                
                with col2:
                    status = "âœ… åˆæ ¼" if result.get('passed') else "âŒ ä¸åˆæ ¼"
                    st.markdown(f"**åˆ¤å®š**: {status}")
                    st.info(f"**è§£é‡ˆ**: {result['interpretation']}")
                    
                    if not result.get('passed') and 'remedy' in result and result['remedy']:
                        st.warning(f"**æ¨å¥¨å¯¾å‡¦æ³•**: {result['remedy']}")
                
                if test_name == 'multicollinearity' and 'data' in result:
                    st.markdown("##### VIFå€¤ã®è©³ç´°")
                    st.dataframe(result['data'].style.background_gradient(cmap='YlOrRd', subset=['VIF']), 
                               use_container_width=True)
                
                if test_name == 'influence' and 'influential_indices' in result and result['influential_indices']:
                    st.markdown("##### å½±éŸ¿åŠ›ã®å¤§ãã„è¦³æ¸¬å€¤ï¼ˆæœ€å¤§10å€‹ï¼‰")
                    st.write(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {result['influential_indices']}")
            else:
                st.warning(f"âš ï¸ {result['interpretation']}")


def display_effect_sizes(effect_sizes):
    """åŠ¹æœé‡ã‚’è¡¨ç¤º"""
    st.markdown("---")
    st.markdown("### ğŸ“Š åŠ¹æœé‡åˆ†æï¼ˆå®Ÿå‹™çš„é‡è¦æ€§ã®è©•ä¾¡ï¼‰")
    
    st.info("ğŸ’¡ på€¤ã¯ã€ŒåŠ¹æœãŒå­˜åœ¨ã™ã‚‹ã‹ã€ã‚’ç¤ºã—ã¾ã™ãŒã€åŠ¹æœé‡ã¯ã€ŒåŠ¹æœãŒã©ã‚Œã ã‘å¤§ãã„ã‹ã€ã‚’ç¤ºã—ã¾ã™")
    
    if effect_sizes.get('cohens_f2'):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Cohen's fÂ²ï¼ˆãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®åŠ¹æœï¼‰", f"{effect_sizes['cohens_f2']['value']:.4f}")
        with col2:
            st.markdown(f"**è§£é‡ˆ**: {effect_sizes['cohens_f2']['interpretation']}")
        st.caption("åŸºæº–: å°(0.02), ä¸­(0.15), å¤§(0.35)")
    
    if effect_sizes.get('standardized_coefficients') is not None:
        st.markdown("---")
        st.markdown("#### æ¨™æº–åŒ–ä¿‚æ•°ï¼ˆBetaï¼‰- å¤‰æ•°é–“ã®ç›´æ¥æ¯”è¼ƒ")
        st.caption("å˜ä½ã®å½±éŸ¿ã‚’é™¤å»ã—ãŸä¿‚æ•°ã€‚çµ¶å¯¾å€¤ãŒå¤§ãã„ã»ã©å½±éŸ¿åŠ›ãŒå¤§ãã„")
        
        fig = px.bar(
            effect_sizes['standardized_coefficients'].head(15),
            x='beta', y='feature', orientation='h',
            title="æ¨™æº–åŒ–ä¿‚æ•°ï¼ˆBetaï¼‰- Top 15",
            color='beta',
            color_continuous_scale='RdBu_r',
            color_continuous_midpoint=0
        )
        fig.update_layout(height=max(400, len(effect_sizes['standardized_coefficients'].head(15)) * 30))
        st.plotly_chart(fig, use_container_width=True)
        
        st.dataframe(effect_sizes['standardized_coefficients'], use_container_width=True)
    
    if effect_sizes.get('partial_r2') is not None:
        st.markdown("---")
        st.markdown("#### å„å¤‰æ•°ã®å¯„ä¸åº¦ï¼ˆPartial RÂ²ï¼‰")
        st.caption("å„å¤‰æ•°ãŒãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ›ï¼ˆRÂ²ï¼‰ã«ã©ã‚Œã ã‘å¯„ä¸ã—ã¦ã„ã‚‹ã‹")
        
        fig2 = px.bar(
            effect_sizes['partial_r2'].head(15),
            x='percentage', y='feature', orientation='h',
            title="èª¬æ˜åŠ›ã¸ã®å¯„ä¸ç‡ï¼ˆ%ï¼‰- Top 15",
            color='percentage',
            color_continuous_scale='Viridis'
        )
        fig2.update_layout(height=max(400, len(effect_sizes['partial_r2'].head(15)) * 30))
        st.plotly_chart(fig2, use_container_width=True)
        
        st.dataframe(effect_sizes['partial_r2'], use_container_width=True)


def display_cv_results(results):
    """ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’è¡¨ç¤º"""
    st.markdown("---")
    st.markdown("### ğŸ”„ ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœï¼ˆéå­¦ç¿’ã®æ¤œè¨¼ï¼‰")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ãƒ†ã‚¹ãƒˆRÂ²ï¼ˆå¹³å‡ï¼‰", f"{results['test_r2_mean']:.4f} Â± {results['test_r2_std']:.4f}")
        st.caption("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ç²¾åº¦")
    
    with col2:
        st.metric("è¨“ç·´RÂ²ï¼ˆå¹³å‡ï¼‰", f"{results['train_r2_mean']:.4f}")
        st.caption("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®é©åˆåº¦")
    
    with col3:
        overfit_status = "âš ï¸ éå­¦ç¿’" if results['is_overfitting'] else "âœ… é©åˆ‡"
        st.metric("éå­¦ç¿’åˆ¤å®š", overfit_status)
        st.caption(f"å·®: {results['overfit_gap']:.4f}")
    
    if results['is_overfitting']:
        st.markdown('<div class="warning-box">âš ï¸ <strong>éå­¦ç¿’ã®å…†å€™</strong></div>', unsafe_allow_html=True)
        st.warning("**æ¨å¥¨å¯¾ç­–**: æ­£å‰‡åŒ–ã®å¼·åŒ–ï¼ˆRidgeã‚„Lassoï¼‰ã€ç‰¹å¾´é‡ã®å‰Šæ¸›ã€ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ åé›†")
    else:
        st.markdown('<div class="success-box">âœ… éå­¦ç¿’ãªã—</div>', unsafe_allow_html=True)
    
    st.markdown("#### ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒ")
    fig = go.Figure()
    fig.add_trace(go.Box(
        y=results['cv_scores']['test_r2'],
        name='Test RÂ²',
        boxmean='sd',
        marker_color='lightblue'
    ))
    fig.add_trace(go.Box(
        y=results['cv_scores']['train_r2'],
        name='Train RÂ²',
        boxmean='sd',
        marker_color='lightgreen'
    ))
    fig.update_layout(
        title="å„Foldã§ã®ã‚¹ã‚³ã‚¢åˆ†å¸ƒ",
        yaxis_title="RÂ² Score",
        showlegend=True
    )
    st.plotly_chart(fig, use_container_width=True)
    
    col_m1, col_m2 = st.columns(2)
    with col_m1:
        st.metric("å¹³å‡äºŒä¹—èª¤å·®ï¼ˆMSEï¼‰", f"{results['test_mse_mean']:.4f}")
    with col_m2:
        st.metric("å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAEï¼‰", f"{results['test_mae_mean']:.4f}")


# ==================== ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•° ====================

def business_impact_simulation(model, X_test, y_test, y_pred, pred_proba=None):
    """Kaggle/Amazonã‚¨ãƒªãƒ¼ãƒˆç´šã®ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    st.markdown("---")
    st.markdown("### ğŸ¯ ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆKaggle/Amazonã‚¨ãƒªãƒ¼ãƒˆç´šï¼‰")
    
    st.info("Monte Carloã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸROIã‚’è¨ˆç®—ã€‚å®Ÿå‹™ã§å³æˆ¦åŠ›ã®æ©Ÿèƒ½ã§ã™")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        customer_base = st.number_input("ç·é¡§å®¢æ•°", min_value=1000, value=10000, step=1000)
        historical_churn_rate = st.slider("æ­´å²çš„é›¢è„±ç‡", 0.01, 0.50, 0.10)
        avg_ltv = st.number_input("å¹³å‡LTVï¼ˆå††ï¼‰", min_value=1000, value=50000, step=5000)
        intervention_cost_per = st.number_input("1äººä»‹å…¥ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰", value=3000, step=500)
        intervention_success_rate_mean = st.slider("ä»‹å…¥æˆåŠŸç‡ï¼ˆå¹³å‡ï¼‰", 0.1, 0.8, 0.4)
        intervention_success_rate_std = st.slider("æˆåŠŸç‡ã®ã°ã‚‰ã¤ãï¼ˆæ¨™æº–åå·®ï¼‰", 0.01, 0.2, 0.05)
    
    with col2:
        st.subheader("ä»‹å…¥æˆ¦ç•¥")
        top_pct = st.slider("ä»‹å…¥å¯¾è±¡ï¼ˆé›¢è„±ç¢ºç‡ä¸Šä½ä½•ï¼…ï¼‰", 1, 50, 10) / 100
        n_simulations = st.number_input("Monte Carloã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å›æ•°", value=1000, step=100)
    
    if st.button("ğŸ”¥ ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆè¨ˆç®—å®Ÿè¡Œ", type="primary", key="impact_calc"):
        
        # äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—ï¼ˆåˆ†é¡ã®å ´åˆæƒ³å®šï¼‰
        if pred_proba is None:
            try:
                if hasattr(model, "predict_proba"):
                    pred_proba = model.predict_proba(X_test)[:, 1]
                else:
                    pred_proba = model.predict(X_test)
                    pred_proba = (pred_proba - pred_proba.min()) / (pred_proba.max() - pred_proba.min() + 1e-8)
            except:
                pred_proba = y_pred
        
        # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è¨ˆç®—ï¼ˆprecision/recall at top_pctï¼‰
        threshold = np.percentile(pred_proba, 100 - (top_pct * 100))
        y_pred_at_threshold = (pred_proba >= threshold).astype(int)
        
        try:
            precision = precision_score(y_test, y_pred_at_threshold, zero_division=0)
            recall = recall_score(y_test, y_pred_at_threshold, zero_division=0)
        except:
            precision = 0.5
            recall = 0.5
        
        st.write(f"ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ï¼ˆä¸Šä½{top_pct*100:.0f}%é–¾å€¤ï¼‰: Precision={precision:.2f}, Recall={recall:.2f}")
        
        # Monte Carloã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        net_savings_list = []
        roi_list = []
        
        for _ in range(n_simulations):
            # ä¸ç¢ºå®Ÿæ€§ã‚’åŠ å‘³ï¼ˆæˆåŠŸç‡ã«ãƒã‚¤ã‚ºï¼‰
            sim_success_rate = np.clip(stats.norm.rvs(intervention_success_rate_mean, intervention_success_rate_std), 0.1, 0.8)
            
            num_identified = customer_base * recall * historical_churn_rate
            customers_saved = num_identified * sim_success_rate
            revenue_retained = customers_saved * avg_ltv
            campaign_cost = num_identified * intervention_cost_per
            
            net_savings = revenue_retained - campaign_cost
            roi = (net_savings / campaign_cost * 100) if campaign_cost > 0 else 0
            
            net_savings_list.append(net_savings)
            roi_list.append(roi)
        
        mean_net = np.mean(net_savings_list)
        mean_roi = np.mean(roi_list)
        ci_net = np.percentile(net_savings_list, [5, 95])
        ci_roi = np.percentile(roi_list, [5, 95])
        
        c1, c2, c3 = st.columns(3)
        c1.metric("å¹³å‡å¹´é–“åˆ©ç›Šæ”¹å–„é¡", f"Â¥{mean_net:,.0f}", f"95%CI: Â¥{ci_net[0]:,.0f} ~ Â¥{ci_net[1]:,.0f}")
        c2.metric("å¹³å‡ROI", f"{mean_roi:.1f}%", f"95%CI: {ci_roi[0]:.1f}% ~ {ci_roi[1]:.1f}%")
        c3.metric("æœŸå¾…æ•‘æ¸ˆé¡§å®¢ï¼ˆå¹´ï¼‰", f"{(customer_base * historical_churn_rate * recall * intervention_success_rate_mean):,.0f}äºº")
        
        # åˆ†å¸ƒã‚°ãƒ©ãƒ•ï¼ˆã‚¨ãƒªãƒ¼ãƒˆç´šã®å¯è¦–åŒ–ï¼‰
        fig = px.histogram(net_savings_list, nbins=50, title="Monte Carloã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœï¼ˆåˆ©ç›Šæ”¹å–„é¡åˆ†å¸ƒï¼‰")
        fig.add_vline(x=mean_net, line_dash="dash", line_color="red", annotation_text="å¹³å‡")
        st.plotly_chart(fig, use_container_width=True)
        
        if mean_net > 0:
            st.markdown(f'<div class="impact-positive">ğŸ’° ä¸Šä½{top_pct*100:.0f}%ä»‹å…¥ã§ã€å¹³å‡ <strong>Â¥{mean_net:,.0f}</strong> ã®åˆ©ç›Šå‰µå‡ºå¯èƒ½ï¼ˆ95%ä¿¡é ¼åŒºé–“å†…ï¼‰ï¼</div>', unsafe_allow_html=True)
        else:
            st.markdown(f'<div class="impact-negative">âš ï¸ ä¸Šä½{top_pct*100:.0f}%ä»‹å…¥ã§ã¯ã€ç¾çŠ¶ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã¯åˆ©ç›Šå‰µå‡ºãŒå›°é›£ã§ã™ã€‚ã‚³ã‚¹ãƒˆå‰Šæ¸›ã¾ãŸã¯æˆåŠŸç‡å‘ä¸Šã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚</div>', unsafe_allow_html=True)
        
        return {
            'mean_net_savings': mean_net,
            'mean_roi': mean_roi,
            'confidence_interval_net': ci_net,
            'confidence_interval_roi': ci_roi,
            'expected_customers_saved': customer_base * historical_churn_rate * recall * intervention_success_rate_mean
        }


# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def load_csv(file_buf):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        file_buf.seek(0)
        df = pd.read_csv(file_buf)
        return df, None
    except Exception as e:
        return None, f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"


def calculate_vif(df, features):
    """VIFï¼ˆå¤šé‡å…±ç·šæ€§ï¼‰ã‚’è¨ˆç®—"""
    try:
        X = df[features].select_dtypes(include=[np.number]).dropna()
        if X.shape[1] < 2:
            return None
        vif_data = pd.DataFrame()
        vif_data["å¤‰æ•°"] = X.columns
        vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
        return vif_data.sort_values('VIF', ascending=False)
    except:
        return None


# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
st.markdown('<div class="main-header">ğŸ“Š Data Science Workflow Studio Pro</div>', unsafe_allow_html=True)
st.markdown('<p style="text-align: center; color: #94a3b8;">çµ±è¨ˆã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã®å³å¯†æ€§ + ã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ©Ÿèƒ½ + ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æ</p>', unsafe_allow_html=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("ğŸ“‹ åˆ†æã‚¹ãƒ†ãƒƒãƒ—")
    steps = [
        "1ï¸âƒ£ å•é¡Œå®šç¾©",
        "2ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ç†è§£ã¨ç‚¹æ¤œ",
        "3ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»EDA",
        "4ï¸âƒ£ ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã¨æ¨å®š",
        "5ï¸âƒ£ è§£é‡ˆã¨ãƒ¬ãƒãƒ¼ãƒˆ"
    ]
    
    current_step = st.radio("ã‚¹ãƒ†ãƒƒãƒ—ã‚’é¸æŠ", steps, index=st.session_state.step - 1)
    st.session_state.step = steps.index(current_step) + 1
    
    st.markdown("---")
    st.markdown("### ğŸ’¡ ç¾åœ¨ã®çŠ¶æ…‹")
    if st.session_state.df is not None:
        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ¸ˆ ({st.session_state.df.shape[0]}è¡Œ)")
    if st.session_state.selected_target:
        st.success(f"âœ… ç›®çš„å¤‰æ•°: {st.session_state.selected_target}")
    if st.session_state.selected_features:
        st.success(f"âœ… èª¬æ˜å¤‰æ•°: {len(st.session_state.selected_features)}å€‹")

# ã‚¹ãƒ†ãƒƒãƒ—1: å•é¡Œå®šç¾©
if st.session_state.step == 1:
    st.markdown('<div class="step-header">1ï¸âƒ£ å•é¡Œå®šç¾©</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    <h4>ğŸ¯ åˆ†æã‚’å§‹ã‚ã‚‹å‰ã«è€ƒãˆã‚‹ã¹ãã“ã¨</h4>
    <ul>
        <li><strong>ãƒ“ã‚¸ãƒã‚¹èª²é¡Œ</strong>: è§£æ±ºã—ãŸã„å®Ÿå‹™ä¸Šã®å•é¡Œã¯ä½•ã§ã™ã‹ï¼Ÿ</li>
        <li><strong>åˆ†æç›®çš„</strong>: è¨˜è¿°ã€æ¨è«–ã€äºˆæ¸¬ã€å› æœæ¨å®šã®ã©ã‚Œã‚’ç›®æŒ‡ã—ã¾ã™ã‹ï¼Ÿ</li>
        <li><strong>æœŸå¾…ã•ã‚Œã‚‹æˆæœ</strong>: ã“ã®åˆ†æã§ä½•ãŒã‚ã‹ã‚Œã°æˆåŠŸã§ã™ã‹ï¼Ÿ</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“ åˆ†æã®ç›®çš„ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„")
        problem_statement = st.text_area(
            "ãƒ“ã‚¸ãƒã‚¹èª²é¡Œã¨åˆ†æç›®çš„",
            height=200,
            placeholder="ä¾‹: å£²ä¸Šã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€ã©ã®è¦å› ãŒå£²ä¸Šã«æœ€ã‚‚å½±éŸ¿ã‚’ä¸ãˆã¦ã„ã‚‹ã‹ã‚’ç‰¹å®šã—ãŸã„ã€‚",
            key="problem_statement"
        )
        
        analysis_goal = st.selectbox(
            "åˆ†æã®ä¸»ãªç›®çš„",
            [
                "é¸æŠã—ã¦ãã ã•ã„",
                "ğŸ“Š è¨˜è¿°çµ±è¨ˆï¼ˆç¾çŠ¶æŠŠæ¡ãƒ»è¦ç´„ï¼‰",
                "ğŸ” æ¨è«–ï¼ˆä»®èª¬æ¤œå®šãƒ»é–¢ä¿‚æ€§ã®æ¤œè¨¼ï¼‰",
                "ğŸ¯ äºˆæ¸¬ï¼ˆå°†æ¥ã®å€¤ã‚’äºˆæ¸¬ï¼‰",
                "âš¡ å› æœæ¨å®šï¼ˆæ–½ç­–åŠ¹æœã®æ¸¬å®šï¼‰",
                "ğŸ”¬ æ¢ç´¢çš„åˆ†æï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹ï¼‰"
            ],
            key="analysis_goal"
        )
        
        expected_outcome = st.text_area(
            "æœŸå¾…ã•ã‚Œã‚‹æˆæœãƒ»ã‚¢ã‚¯ã‚·ãƒ§ãƒ³",
            height=150,
            placeholder="ä¾‹: é‡è¦ãªèª¬æ˜å¤‰æ•°ãƒˆãƒƒãƒ—3ã‚’ç‰¹å®šã—ã€ãã‚Œã‚‰ã«é›†ä¸­æŠ•è³‡ã™ã‚‹æˆ¦ç•¥ã‚’ç«‹æ¡ˆã™ã‚‹ã€‚",
            key="expected_outcome"
        )
    
    with col2:
        st.subheader("ğŸ“Œ åˆ†æè¨­è¨ˆã®ãƒ’ãƒ³ãƒˆ")
        st.markdown("""
        <div style="background-color: #1e293b; padding: 1rem; border-radius: 10px;">
        <h5>è¨˜è¿°çµ±è¨ˆã®å ´åˆ</h5>
        <p>â†’ å¹³å‡ã€ä¸­å¤®å€¤ã€åˆ†å¸ƒã®å¯è¦–åŒ–</p>
        
        <h5>æ¨è«–ã®å ´åˆ</h5>
        <p>â†’ tæ¤œå®šã€ANOVAã€å›å¸°åˆ†æã§é–¢ä¿‚æ€§ã‚’æ¤œè¨¼</p>
        
        <h5>äºˆæ¸¬ã®å ´åˆ</h5>
        <p>â†’ æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ç²¾åº¦é‡è¦–</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    if problem_statement and analysis_goal != "é¸æŠã—ã¦ãã ã•ã„":
        st.markdown('<div class="success-box">âœ… å•é¡Œå®šç¾©ãŒå®Œäº†ã—ã¾ã—ãŸ</div>', unsafe_allow_html=True)
        if st.button("â¡ï¸ ã‚¹ãƒ†ãƒƒãƒ—2ã¸é€²ã‚€", type="primary"):
            st.session_state.step = 2
            st.rerun()
    else:
        st.warning("âš ï¸ åˆ†æç›®çš„ã‚’æ˜ç¢ºã«ã—ã¦ã‹ã‚‰æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã‚“ã§ãã ã•ã„ã€‚")

# ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿ç†è§£ã¨ç‚¹æ¤œ
elif st.session_state.step == 2:
    st.markdown('<div class="step-header">2ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ç†è§£ã¨ç‚¹æ¤œ</div>', unsafe_allow_html=True)
    
    uploaded_file = st.file_uploader("ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['csv'])
    
    col_sample1, col_sample2 = st.columns([1, 3])
    with col_sample1:
        if st.button('ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ'):
            np.random.seed(42)
            sample_df = pd.DataFrame({
                'age': np.random.randint(22, 65, 500),
                'income': (np.random.normal(50000, 12000, 500)).astype(int),
                'experience': np.random.randint(0, 30, 500),
                'education': np.random.choice(['HS', 'BSc', 'MSc', 'PhD'], 500),
                'group': np.random.choice(['A', 'B', 'C'], 500),
                'outcome': np.random.normal(100, 20, 500)
            })
            st.session_state.df = sample_df
            st.success("âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            st.rerun()
    
    if uploaded_file is not None:
        result, error = load_csv(uploaded_file)
        if error:
            st.error(error)
        else:
            df = result
            st.session_state.df = df
            st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
    
    if st.session_state.df is not None:
        df = st.session_state.df
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ç·è¡Œæ•°", df.shape[0])
        col2.metric("ç·åˆ—æ•°", df.shape[1])
        col3.metric("æ•°å€¤åˆ—", len(df.select_dtypes(include=[np.number]).columns))
        col4.metric("æ¬ æå€¤ã‚ã‚Š", df.isnull().any().sum())
        
        st.markdown("---")
        
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ğŸ·ï¸ å¤‰æ•°åç·¨é›†", "ğŸ¯ å¤‰æ•°é¸æŠ", "ğŸ“Š åŸºæœ¬çµ±è¨ˆ"])
        
        with tab1:
            st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(df.head(100), use_container_width=True)
            
            st.subheader("ãƒ‡ãƒ¼ã‚¿å‹æƒ…å ±")
            dtype_df = pd.DataFrame({
                'åˆ—å': df.columns,
                'ãƒ‡ãƒ¼ã‚¿å‹': df.dtypes.values,
                'æ¬ ææ•°': df.isnull().sum().values,
                'æ¬ æç‡(%)': (df.isnull().sum() / len(df) * 100).round(2).values,
                'ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°': [df[col].nunique() for col in df.columns]
            })
            st.dataframe(dtype_df, use_container_width=True)
        
        with tab2:
            st.subheader("ğŸ·ï¸ å¤‰æ•°åã‚’ã‚ã‹ã‚Šã‚„ã™ãç·¨é›†")
            
            if not st.session_state.column_mapping:
                st.session_state.column_mapping = {col: col for col in df.columns}
            
            col_edit1, col_edit2 = st.columns(2)
            
            with col_edit1:
                st.markdown("**å…ƒã®åˆ—å**")
                for col in df.columns:
                    st.text(col)
            
            with col_edit2:
                st.markdown("**æ–°ã—ã„åˆ—å**")
                for col in df.columns:
                    new_name = st.text_input(
                        f"rename_{col}",
                        value=st.session_state.column_mapping.get(col, col),
                        label_visibility="collapsed",
                        key=f"rename_{col}"
                    )
                    st.session_state.column_mapping[col] = new_name
            
            if st.button("âœ… å¤‰æ•°åã‚’ç¢ºå®š", type="primary"):
                new_names = list(st.session_state.column_mapping.values())
                if len(new_names) != len(set(new_names)):
                    st.error("âŒ é‡è¤‡ã™ã‚‹å¤‰æ•°åãŒã‚ã‚Šã¾ã™")
                else:
                    df_renamed = df.rename(columns=st.session_state.column_mapping)
                    st.session_state.df = df_renamed
                    st.success("âœ… å¤‰æ•°åã‚’æ›´æ–°ã—ã¾ã—ãŸ")
                    st.rerun()
        
        with tab3:
            st.subheader("ğŸ¯ ç›®çš„å¤‰æ•°ã¨èª¬æ˜å¤‰æ•°ã®é¸æŠ")
            
            target_col = st.selectbox(
                "ç›®çš„å¤‰æ•°ã‚’é¸æŠ",
                options=['é¸æŠã—ã¦ãã ã•ã„'] + list(df.columns),
                key="target_selection"
            )
            
            if target_col != 'é¸æŠã—ã¦ãã ã•ã„':
                st.session_state.selected_target = target_col
                
                feature_candidates = [col for col in df.columns if col != target_col]
                
                st.markdown("---")
                st.markdown("#### èª¬æ˜å¤‰æ•°ã‚’é¸æŠ")
                
                col_btn1, col_btn2 = st.columns(2)
                with col_btn1:
                    if st.button("âœ… ã™ã¹ã¦é¸æŠ"):
                        st.session_state.selected_features = feature_candidates
                        st.rerun()
                with col_btn2:
                    if st.button("âŒ ã™ã¹ã¦è§£é™¤"):
                        st.session_state.selected_features = []
                        st.rerun()
                
                selected_features = st.multiselect(
                    "ä½¿ç”¨ã™ã‚‹èª¬æ˜å¤‰æ•°",
                    options=feature_candidates,
                    default=[f for f in st.session_state.selected_features if f in feature_candidates] if st.session_state.selected_features else feature_candidates,
                    key="feature_selection"
                )
                st.session_state.selected_features = selected_features
                
                if selected_features:
                    st.success(f"âœ… ç›®çš„å¤‰æ•°: **{target_col}** | èª¬æ˜å¤‰æ•°: **{len(selected_features)}å€‹**")
                    
                    st.markdown("#### é¸æŠã—ãŸå¤‰æ•°ã®ã‚µãƒãƒª")
                    selected_df = df[[target_col] + selected_features]
                    st.dataframe(selected_df.describe(), use_container_width=True)
        
        with tab4:
            st.subheader("ğŸ“Š åŸºæœ¬çµ±è¨ˆé‡ã¨å¯è¦–åŒ–")
            
            if st.session_state.selected_features:
                viz_col = st.selectbox(
                    "å¯è¦–åŒ–ã™ã‚‹å¤‰æ•°ã‚’é¸æŠ",
                    options=[st.session_state.selected_target] + st.session_state.selected_features
                )
                
                col_viz1, col_viz2 = st.columns(2)
                
                with col_viz1:
                    if pd.api.types.is_numeric_dtype(df[viz_col]):
                        fig = px.histogram(
                            df, x=viz_col,
                            title=f"åˆ†å¸ƒ: {viz_col}",
                            marginal="box"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        vc = df[viz_col].value_counts().reset_index()
                        vc.columns = [viz_col, 'count']
                        fig = px.bar(vc, x=viz_col, y='count', title=f"é »åº¦: {viz_col}")
                        st.plotly_chart(fig, use_container_width=True)
                
                with col_viz2:
                    st.markdown("**åŸºæœ¬çµ±è¨ˆé‡**")
                    if pd.api.types.is_numeric_dtype(df[viz_col]):
                        stats_dict = {
                            'å¹³å‡': df[viz_col].mean(),
                            'ä¸­å¤®å€¤': df[viz_col].median(),
                            'æ¨™æº–åå·®': df[viz_col].std(),
                            'æœ€å°å€¤': df[viz_col].min(),
                            'æœ€å¤§å€¤': df[viz_col].max(),
                            'æ¬ ææ•°': df[viz_col].isnull().sum()
                        }
                        st.table(pd.DataFrame(stats_dict.items(), columns=['çµ±è¨ˆé‡', 'å€¤']))
                    else:
                        st.write(df[viz_col].value_counts())
                
                if len(st.session_state.selected_features) >= 2:
                    st.markdown("---")
                    st.markdown("#### ç›¸é–¢è¡Œåˆ—")
                    numeric_features = [col for col in st.session_state.selected_features if pd.api.types.is_numeric_dtype(df[col])]
                    if numeric_features:
                        corr_df = df[[st.session_state.selected_target] + numeric_features].corr()
                        fig_corr = px.imshow(
                            corr_df,
                            text_auto='.2f',
                            title="ç›¸é–¢è¡Œåˆ—",
                            color_continuous_scale='RdBu_r',
                            zmin=-1, zmax=1
                        )
                        st.plotly_chart(fig_corr, use_container_width=True)
        
        st.markdown("---")
        if st.session_state.selected_target and st.session_state.selected_features:
            if st.button("â¡ï¸ ã‚¹ãƒ†ãƒƒãƒ—3ã¸é€²ã‚€ï¼ˆãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼‰", type="primary"):
                st.session_state.step = 3
                st.rerun()
        else:
            st.warning("âš ï¸ ç›®çš„å¤‰æ•°ã¨èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
    else:
        st.info("ğŸ’¡ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")

# ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»EDA
elif st.session_state.step == 3:
    st.markdown('<div class="step-header">3ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»EDA</div>', unsafe_allow_html=True)
    
    if st.session_state.df is None:
        st.warning("âš ï¸ ã‚¹ãƒ†ãƒƒãƒ—2ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        if st.button("â¬…ï¸ ã‚¹ãƒ†ãƒƒãƒ—2ã«æˆ»ã‚‹"):
            st.session_state.step = 2
            st.rerun()
        st.stop()
    
    df = st.session_state.df.copy()
    target = st.session_state.selected_target
    features = st.session_state.selected_features
    
    if not target or not features:
        st.warning("âš ï¸ ã‚¹ãƒ†ãƒƒãƒ—2ã§ç›®çš„å¤‰æ•°ã¨èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
        if st.button("â¬…ï¸ ã‚¹ãƒ†ãƒƒãƒ—2ã«æˆ»ã‚‹"):
            st.session_state.step = 2
            st.rerun()
        st.stop()
    
    if st.session_state.processed_df is None:
        st.session_state.processed_df = df[[target] + features].copy()
    
    work_df = st.session_state.processed_df.copy()
    
    st.info(f"ç›®çš„å¤‰æ•°: **{target}** | èª¬æ˜å¤‰æ•°: **{len(features)}å€‹**")
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ”§ æ¬ æå€¤å‡¦ç†",
        "ğŸ“‰ å¤–ã‚Œå€¤å‡¦ç†",
        "ğŸ”„ ãƒ‡ãƒ¼ã‚¿å¤‰æ›",
        "ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°å‡¦ç†",
        "ğŸ’¾ å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿"
    ])
    
    with tab1:
        st.subheader("ğŸ”§ æ¬ æå€¤è£œå®Œ")
        
        missing_info = pd.DataFrame({
            'å¤‰æ•°': work_df.columns,
            'æ¬ ææ•°': work_df.isnull().sum().values,
            'æ¬ æç‡(%)': (work_df.isnull().sum() / len(work_df) * 100).round(2).values
        })
        missing_info = missing_info[missing_info['æ¬ ææ•°'] > 0]
        
        if len(missing_info) > 0:
            st.dataframe(missing_info, use_container_width=True)
            
            st.markdown("---")
            impute_method = st.selectbox(
                "è£œå®Œæ–¹æ³•ã‚’é¸æŠ",
                ["é¸æŠã—ã¦ãã ã•ã„", "å¹³å‡å€¤", "ä¸­å¤®å€¤", "æœ€é »å€¤", "å‰Šé™¤"]
            )
            
            if impute_method != "é¸æŠã—ã¦ãã ã•ã„":
                impute_cols = st.multiselect(
                    "è£œå®Œã™ã‚‹å¤‰æ•°ã‚’é¸æŠ",
                    options=missing_info['å¤‰æ•°'].tolist()
                )
                
                if st.button("âœ… è£œå®Œå®Ÿè¡Œ", type="primary") and impute_cols:
                    for col in impute_cols:
                        if impute_method == "å¹³å‡å€¤":
                            work_df[col].fillna(work_df[col].mean(), inplace=True)
                        elif impute_method == "ä¸­å¤®å€¤":
                            work_df[col].fillna(work_df[col].median(), inplace=True)
                        elif impute_method == "æœ€é »å€¤":
                            work_df[col].fillna(work_df[col].mode()[0], inplace=True)
                        elif impute_method == "å‰Šé™¤":
                            work_df.dropna(subset=[col], inplace=True)
                    
                    st.session_state.processed_df = work_df
                    st.success(f"âœ… {len(impute_cols)}å€‹ã®å¤‰æ•°ã®æ¬ æå€¤ã‚’è£œå®Œã—ã¾ã—ãŸ")
                    st.rerun()
        else:
            st.success("âœ… æ¬ æå€¤ã¯ã‚ã‚Šã¾ã›ã‚“")
    
    with tab2:
        st.subheader("ğŸ“‰ å¤–ã‚Œå€¤å‡¦ç†")
        
        numeric_cols = work_df.select_dtypes(include=[np.number]).columns.tolist()
        
        if numeric_cols:
            outlier_col = st.selectbox("å¤–ã‚Œå€¤ã‚’ç¢ºèªã™ã‚‹å¤‰æ•°", options=numeric_cols)
            
            # é‡è¤‡åˆ—åã‚’ãƒã‚§ãƒƒã‚¯
            if work_df.columns.duplicated().any():
                st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã«é‡è¤‡ã—ãŸåˆ—åãŒã‚ã‚Šã¾ã™ã€‚ã‚¹ãƒ†ãƒƒãƒ—3ã®ã€Œå‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã€ã‚¿ãƒ–ã§ç¢ºèªã—ã¦ãã ã•ã„")
                duplicates = work_df.columns[work_df.columns.duplicated()].tolist()
                st.write(f"é‡è¤‡ã—ã¦ã„ã‚‹åˆ—: {list(set(duplicates))}")
                
                if st.button("ğŸ”§ é‡è¤‡åˆ—ã‚’è‡ªå‹•å‰Šé™¤"):
                    # é‡è¤‡åˆ—ã‚’å‰Šé™¤ï¼ˆæœ€åˆã®ã‚‚ã®ã‚’æ®‹ã™ï¼‰
                    work_df = work_df.loc[:, ~work_df.columns.duplicated()]
                    st.session_state.processed_df = work_df
                    st.success("âœ… é‡è¤‡åˆ—ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                    st.rerun()
            else:
                fig = px.box(work_df, y=outlier_col, title=f"{outlier_col} ã®ç®±ã²ã’å›³")
                st.plotly_chart(fig, use_container_width=True)
                
                Q1 = work_df[outlier_col].quantile(0.25)
                Q3 = work_df[outlier_col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                outliers = work_df[(work_df[outlier_col] < lower_bound) | (work_df[outlier_col] > upper_bound)]
                
                st.write(f"**å¤–ã‚Œå€¤æ¤œå‡º**: {len(outliers)}ä»¶ ({len(outliers)/len(work_df)*100:.2f}%)")
                st.write(f"ä¸‹é™: {lower_bound:.2f}, ä¸Šé™: {upper_bound:.2f}")
                
                st.markdown("---")
                outlier_method = st.selectbox(
                    "å¤–ã‚Œå€¤å‡¦ç†æ–¹æ³•",
                    ["é¸æŠã—ã¦ãã ã•ã„", "Winsorizationï¼ˆå¢ƒç•Œå€¤ã§ç½®æ›ï¼‰", "Trimmingï¼ˆå‰Šé™¤ï¼‰", "å¯¾æ•°å¤‰æ›"]
                )
                
                if outlier_method != "é¸æŠã—ã¦ãã ã•ã„":
                    if st.button("âœ… å¤–ã‚Œå€¤å‡¦ç†å®Ÿè¡Œ", type="primary"):
                        if outlier_method == "Winsorizationï¼ˆå¢ƒç•Œå€¤ã§ç½®æ›ï¼‰":
                            work_df[outlier_col] = work_df[outlier_col].clip(lower=lower_bound, upper=upper_bound)
                            st.success("âœ… Winsorizationå®Œäº†")
                        elif outlier_method == "Trimmingï¼ˆå‰Šé™¤ï¼‰":
                            work_df = work_df[(work_df[outlier_col] >= lower_bound) & (work_df[outlier_col] <= upper_bound)]
                            st.success(f"âœ… {len(outliers)}ä»¶ã®å¤–ã‚Œå€¤ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                        elif outlier_method == "å¯¾æ•°å¤‰æ›":
                            work_df[outlier_col] = np.log1p(work_df[outlier_col].clip(lower=0))
                            st.success("âœ… å¯¾æ•°å¤‰æ›å®Œäº†")
                        
                        st.session_state.processed_df = work_df
                        st.rerun()
        else:
            st.info("æ•°å€¤å¤‰æ•°ãŒã‚ã‚Šã¾ã›ã‚“")
    
    with tab3:
        st.subheader("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å¤‰æ›")
        
        numeric_cols = work_df.select_dtypes(include=[np.number]).columns.tolist()
        
        if numeric_cols:
            transform_cols = st.multiselect("å¤‰æ›ã™ã‚‹å¤‰æ•°ã‚’é¸æŠ", options=numeric_cols)
            
            if transform_cols:
                transform_method = st.selectbox(
                    "å¤‰æ›æ–¹æ³•",
                    ["é¸æŠã—ã¦ãã ã•ã„", "æ¨™æº–åŒ–ï¼ˆZ-scoreï¼‰", "æ­£è¦åŒ–ï¼ˆMin-Maxï¼‰", "å¯¾æ•°å¤‰æ›", "å¹³æ–¹æ ¹å¤‰æ›"]
                )
                
                if transform_method != "é¸æŠã—ã¦ãã ã•ã„" and st.button("âœ… å¤‰æ›å®Ÿè¡Œ", type="primary"):
                    for col in transform_cols:
                        if transform_method == "æ¨™æº–åŒ–ï¼ˆZ-scoreï¼‰":
                            work_df[f"{col}_std"] = (work_df[col] - work_df[col].mean()) / work_df[col].std()
                        elif transform_method == "æ­£è¦åŒ–ï¼ˆMin-Maxï¼‰":
                            work_df[f"{col}_norm"] = (work_df[col] - work_df[col].min()) / (work_df[col].max() - work_df[col].min())
                        elif transform_method == "å¯¾æ•°å¤‰æ›":
                            work_df[f"{col}_log"] = np.log1p(work_df[col].clip(lower=0))
                        elif transform_method == "å¹³æ–¹æ ¹å¤‰æ›":
                            work_df[f"{col}_sqrt"] = np.sqrt(work_df[col].clip(lower=0))
                    
                    st.session_state.processed_df = work_df
                    st.success(f"âœ… {len(transform_cols)}å€‹ã®å¤‰æ•°ã‚’å¤‰æ›ã—ã¾ã—ãŸ")
                    st.rerun()
        else:
            st.info("æ•°å€¤å¤‰æ•°ãŒã‚ã‚Šã¾ã›ã‚“")
    
    with tab4:
        st.subheader("ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°")
        
        cat_cols = work_df.select_dtypes(include=['object', 'category']).columns.tolist()
        
        if cat_cols:
            st.write(f"ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°: {len(cat_cols)}å€‹")
            
            encode_col = st.selectbox("ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹å¤‰æ•°", options=cat_cols)
            
            if encode_col:
                st.write(f"**{encode_col}** ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤æ•°: {work_df[encode_col].nunique()}")
                st.write("å€¤ã®ä¾‹:", work_df[encode_col].value_counts().head(10))
                
                encode_method = st.selectbox(
                    "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ–¹æ³•",
                    ["é¸æŠã—ã¦ãã ã•ã„", "Label Encodingï¼ˆåºæ•°ï¼‰", "One-Hot Encodingï¼ˆãƒ€ãƒŸãƒ¼å¤‰æ•°ï¼‰", "é »åº¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"]
                )
                
                if encode_method != "é¸æŠã—ã¦ãã ã•ã„" and st.button("âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ", type="primary"):
                    if encode_method == "Label Encodingï¼ˆåºæ•°ï¼‰":
                        new_col_name = f"{encode_col}_encoded"
                        if new_col_name not in work_df.columns:
                            le = LabelEncoder()
                            work_df[new_col_name] = le.fit_transform(work_df[encode_col].astype(str))
                            st.success(f"âœ… {encode_col}ã‚’Label Encodingã—ã¾ã—ãŸ â†’ {new_col_name}")
                        else:
                            st.warning(f"âš ï¸ {new_col_name} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
                            
                    elif encode_method == "One-Hot Encodingï¼ˆãƒ€ãƒŸãƒ¼å¤‰æ•°ï¼‰":
                        # æ—¢å­˜ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°ã‚’ãƒã‚§ãƒƒã‚¯
                        existing_dummies = [col for col in work_df.columns if col.startswith(f"{encode_col}_")]
                        
                        if existing_dummies:
                            st.warning(f"âš ï¸ {encode_col} ã® One-Hot Encodingåˆ—ãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™: {existing_dummies}")
                            if st.checkbox(f"æ—¢å­˜ã®åˆ—ã‚’å‰Šé™¤ã—ã¦å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿ"):
                                work_df = work_df.drop(columns=existing_dummies)
                                dummies = pd.get_dummies(work_df[encode_col], prefix=encode_col, drop_first=True)
                                work_df = pd.concat([work_df, dummies], axis=1)
                                st.success(f"âœ… {encode_col}ã‚’å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼ˆ{len(dummies.columns)}å€‹ã®æ–°å¤‰æ•°ï¼‰")
                                st.session_state.processed_df = work_df
                                st.rerun()
                        else:
                            dummies = pd.get_dummies(work_df[encode_col], prefix=encode_col, drop_first=True)
                            work_df = pd.concat([work_df, dummies], axis=1)
                            st.success(f"âœ… {encode_col}ã‚’One-Hot Encodingã—ã¾ã—ãŸï¼ˆ{len(dummies.columns)}å€‹ã®æ–°å¤‰æ•°ï¼‰")
                            
                    elif encode_method == "é »åº¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°":
                        new_col_name = f"{encode_col}_freq"
                        if new_col_name not in work_df.columns:
                            freq_map = work_df[encode_col].value_counts(normalize=True).to_dict()
                            work_df[new_col_name] = work_df[encode_col].map(freq_map)
                            st.success(f"âœ… {encode_col}ã‚’é »åº¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã—ãŸ â†’ {new_col_name}")
                        else:
                            st.warning(f"âš ï¸ {new_col_name} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
                    
                    st.session_state.processed_df = work_df
                    st.rerun()
        else:
            st.info("ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ãŒã‚ã‚Šã¾ã›ã‚“")
    
    with tab5:
        st.subheader("ğŸ’¾ å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿")
        
        # é‡è¤‡åˆ—åãƒã‚§ãƒƒã‚¯
        if work_df.columns.duplicated().any():
            st.error("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã«é‡è¤‡ã—ãŸåˆ—åãŒã‚ã‚Šã¾ã™")
            duplicates = work_df.columns[work_df.columns.duplicated()].tolist()
            st.write(f"é‡è¤‡ã—ã¦ã„ã‚‹åˆ—: {list(set(duplicates))}")
            
            if st.button("ğŸ”§ é‡è¤‡åˆ—ã‚’è‡ªå‹•å‰Šé™¤", type="primary"):
                work_df = work_df.loc[:, ~work_df.columns.duplicated()]
                st.session_state.processed_df = work_df
                st.success("âœ… é‡è¤‡åˆ—ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                st.rerun()
        
        st.write(f"**ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿**: {work_df.shape[0]}è¡Œ Ã— {work_df.shape[1]}åˆ—")
        
        st.dataframe(work_df.head(100), use_container_width=True)
        
        st.markdown("---")
        st.markdown("#### åŸºæœ¬çµ±è¨ˆé‡")
        st.dataframe(work_df.describe(), use_container_width=True)
        
        st.markdown("---")
        st.markdown("#### åˆ—åä¸€è¦§")
        col_info = pd.DataFrame({
            'åˆ—å': work_df.columns,
            'ãƒ‡ãƒ¼ã‚¿å‹': work_df.dtypes.values,
            'æ¬ ææ•°': work_df.isnull().sum().values
        })
        st.dataframe(col_info, use_container_width=True)
        
        st.markdown("---")
        csv = work_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            "ğŸ“¥ å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (CSV)",
            data=csv,
            file_name="processed_data.csv",
            mime="text/csv",
            type="primary"
        )
        
        if st.button("âœ… ã“ã®å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§åˆ†æã‚’ç¶šã‘ã‚‹", type="primary"):
            # æœ€çµ‚ãƒã‚§ãƒƒã‚¯
            if work_df.columns.duplicated().any():
                st.error("âŒ é‡è¤‡åˆ—åã‚’å‰Šé™¤ã—ã¦ã‹ã‚‰ç¶šã‘ã¦ãã ã•ã„")
            else:
                st.session_state.processed_df = work_df
                st.success("âœ… å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºå®šã—ã¾ã—ãŸ")
    
    st.markdown("---")
    if st.button("â¡ï¸ ã‚¹ãƒ†ãƒƒãƒ—4ã¸é€²ã‚€ï¼ˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼‰", type="primary"):
        st.session_state.processed_df = work_df
        st.session_state.step = 4
        st.rerun()

# ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã¨æ¨å®š
elif st.session_state.step == 4:
    st.markdown('<div class="step-header">4ï¸âƒ£ ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã¨æ¨å®š</div>', unsafe_allow_html=True)
    
    if st.session_state.processed_df is None:
        st.warning("âš ï¸ ã‚¹ãƒ†ãƒƒãƒ—3ã§ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’å®Œäº†ã—ã¦ãã ã•ã„")
        if st.button("â¬…ï¸ ã‚¹ãƒ†ãƒƒãƒ—3ã«æˆ»ã‚‹"):
            st.session_state.step = 3
            st.rerun()
        st.stop()
    
    df = st.session_state.processed_df.copy()
    target = st.session_state.selected_target
    
    if target not in df.columns:
        st.error(f"âŒ ç›®çš„å¤‰æ•° '{target}' ãŒãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ã¾ã›ã‚“")
        st.stop()
    
    numeric_features = [col for col in df.columns if col != target and pd.api.types.is_numeric_dtype(df[col])]
    
    if not numeric_features:
        st.error("âŒ æ•°å€¤å‹ã®èª¬æ˜å¤‰æ•°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ãƒ†ãƒƒãƒ—3ã§ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        if st.button("â¬…ï¸ ã‚¹ãƒ†ãƒƒãƒ—3ã«æˆ»ã‚‹"):
            st.session_state.step = 3
            st.rerun()
        st.stop()
    
    st.info(f"ç›®çš„å¤‰æ•°: **{target}** | ä½¿ç”¨å¯èƒ½ãªèª¬æ˜å¤‰æ•°: **{len(numeric_features)}å€‹**")
    
    st.markdown("---")
    st.subheader("ğŸ“Š åˆ†æç›®çš„ã‚’é¸æŠ")
    
    analysis_type = st.selectbox(
        "å®Ÿè¡Œã—ãŸã„åˆ†æ",
        [
            "é¸æŠã—ã¦ãã ã•ã„",
            "ğŸ“Š è¨˜è¿°çµ±è¨ˆï¼ˆå¹³å‡ãƒ»åˆ†æ•£ãƒ»åˆ†å¸ƒæ¯”è¼ƒï¼‰",
            "ğŸ” æ¨è«–ï¼ˆtæ¤œå®šãƒ»ANOVAãƒ»ç›¸é–¢åˆ†æï¼‰",
            "ğŸ“ˆ å›å¸°åˆ†æï¼ˆçµ±è¨ˆçš„å³å¯†æ€§å¼·åŒ–ç‰ˆï¼‰",
            "ğŸ¯ äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆæ©Ÿæ¢°å­¦ç¿’ï¼‰",
            "ğŸš€ å›å¸°åˆ†æï¼ˆè‡ªå‹•æœ€é©åŒ–ï¼‰",
            "ğŸ¤– äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆè‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰"
        ]
    )
    
    if analysis_type == "é¸æŠã—ã¦ãã ã•ã„":
        st.warning("âš ï¸ åˆ†æã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„")
        st.stop()
    
    # è¨˜è¿°çµ±è¨ˆ
    if analysis_type == "ğŸ“Š è¨˜è¿°çµ±è¨ˆï¼ˆå¹³å‡ãƒ»åˆ†æ•£ãƒ»åˆ†å¸ƒæ¯”è¼ƒï¼‰":
        st.markdown("### è¨˜è¿°çµ±è¨ˆåˆ†æ")
        
        desc_var = st.selectbox("åˆ†æã™ã‚‹å¤‰æ•°", options=[target] + numeric_features)
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_hist = px.histogram(df, x=desc_var, title=f"{desc_var} ã®åˆ†å¸ƒ", marginal="box")
            st.plotly_chart(fig_hist, use_container_width=True)
        
        with col2:
            stats_dict = {
                'å¹³å‡': df[desc_var].mean(),
                'ä¸­å¤®å€¤': df[desc_var].median(),
                'æ¨™æº–åå·®': df[desc_var].std(),
                'åˆ†æ•£': df[desc_var].var(),
                'æœ€å°å€¤': df[desc_var].min(),
                'æœ€å¤§å€¤': df[desc_var].max(),
                'æ­ªåº¦': df[desc_var].skew(),
                'å°–åº¦': df[desc_var].kurtosis()
            }
            st.table(pd.DataFrame(stats_dict.items(), columns=['çµ±è¨ˆé‡', 'å€¤']))
    
    # æ¨è«–
    elif analysis_type == "ğŸ” æ¨è«–ï¼ˆtæ¤œå®šãƒ»ANOVAãƒ»ç›¸é–¢åˆ†æï¼‰":
        st.markdown("### çµ±è¨ˆçš„æ¨è«–")
        
        test_type = st.selectbox("æ¤œå®šã‚¿ã‚¤ãƒ—", ["ç›¸é–¢åˆ†æ", "tæ¤œå®šï¼ˆ2ç¾¤æ¯”è¼ƒï¼‰"])
        
        if test_type == "ç›¸é–¢åˆ†æ":
            st.subheader("ç›¸é–¢åˆ†æ")
            
            corr_features = st.multiselect(
                "ç›¸é–¢ã‚’åˆ†æã™ã‚‹å¤‰æ•°",
                options=[target] + numeric_features,
                default=[target] + numeric_features[:min(5, len(numeric_features))]
            )
            
            if len(corr_features) >= 2:
                corr_matrix = df[corr_features].corr()
                
                fig_corr = px.imshow(
                    corr_matrix,
                    text_auto='.2f',
                    title="ç›¸é–¢è¡Œåˆ—",
                    color_continuous_scale='RdBu_r',
                    zmin=-1, zmax=1
                )
                st.plotly_chart(fig_corr, use_container_width=True)
                
                st.markdown("#### ç›¸é–¢ãŒé«˜ã„å¤‰æ•°ãƒšã‚¢ï¼ˆä¸Šä½5çµ„ï¼‰")
                corr_pairs = []
                for i in range(len(corr_matrix.columns)):
                    for j in range(i+1, len(corr_matrix.columns)):
                        corr_pairs.append({
                            'å¤‰æ•°1': corr_matrix.columns[i],
                            'å¤‰æ•°2': corr_matrix.columns[j],
                            'ç›¸é–¢ä¿‚æ•°': corr_matrix.iloc[i, j]
                        })
                corr_pairs_df = pd.DataFrame(corr_pairs).sort_values('ç›¸é–¢ä¿‚æ•°', ascending=False, key=abs)
                st.dataframe(corr_pairs_df.head(5), use_container_width=True)
    
    # å›å¸°åˆ†æï¼ˆçµ±è¨ˆçš„å³å¯†æ€§å¼·åŒ–ç‰ˆï¼‰
    elif analysis_type == "ğŸ“ˆ å›å¸°åˆ†æï¼ˆçµ±è¨ˆçš„å³å¯†æ€§å¼·åŒ–ç‰ˆï¼‰":
        st.markdown("### é‡å›å¸°åˆ†æï¼ˆçµ±è¨ˆã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ï¼‰")
        
        st.info("çµ±è¨ˆçš„å‰ææ¡ä»¶ã®æ¤œè¨¼ã€åŠ¹æœé‡ã®è¨ˆç®—ã€ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å«ã‚€å³å¯†ãªå›å¸°åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™")
        
        selected_features = st.multiselect(
            "å›å¸°åˆ†æã«ä½¿ç”¨ã™ã‚‹èª¬æ˜å¤‰æ•°",
            options=numeric_features,
            default=numeric_features[:min(10, len(numeric_features))]
        )
        
        if len(selected_features) == 0:
            st.warning("âš ï¸ èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
            st.stop()
        
        regression_df = df[[target] + selected_features].dropna()
        
        if len(regression_df) == 0:
            st.error("âŒ æ¬ æå€¤ã‚’é™¤å¤–ã™ã‚‹ã¨ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã‚Šã¾ã›ã‚“")
            st.stop()
        
        st.write(f"**ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿**: {len(regression_df)}è¡Œ")
        
        model_type = st.selectbox(
            "ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—",
            ["é€šå¸¸ã®ç·šå½¢å›å¸°ï¼ˆOLSï¼‰", "Ridgeå›å¸°ï¼ˆæ­£å‰‡åŒ–ï¼‰", "Lassoå›å¸°ï¼ˆå¤‰æ•°é¸æŠï¼‰"]
        )
        
        with st.expander("ğŸ”§ é«˜åº¦ãªè¨­å®š"):
            test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ", 0.1, 0.4, 0.2, 0.05)
            enable_cv = st.checkbox("ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ", value=True)
            cv_folds = st.slider("CVã®foldæ•°", 3, 10, 5) if enable_cv else 5
            random_state = 42
        
        if st.button("âœ… å›å¸°åˆ†æå®Ÿè¡Œ", type="primary"):
            X = regression_df[selected_features]
            y = regression_df[target]
            
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
            
            with st.spinner("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­..."):
                X_train_sm = sm.add_constant(X_train)
                X_test_sm = sm.add_constant(X_test)
                
                if model_type == "é€šå¸¸ã®ç·šå½¢å›å¸°ï¼ˆOLSï¼‰":
                    model_sm = sm.OLS(y_train, X_train_sm).fit()
                    y_pred = model_sm.predict(X_test_sm)
                    residuals = model_sm.resid
                    
                elif model_type == "Ridgeå›å¸°ï¼ˆæ­£å‰‡åŒ–ï¼‰":
                    alpha = st.slider("æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆÎ±ï¼‰", 0.01, 10.0, 1.0)
                    model_sklearn = Ridge(alpha=alpha)
                    model_sklearn.fit(X_train, y_train)
                    y_pred = model_sklearn.predict(X_test)
                    
                    model_sm = sm.OLS(y_train, X_train_sm).fit()
                    residuals = y_train - model_sm.predict(X_train_sm)
                    
                else:
                    alpha = st.slider("æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆÎ±ï¼‰", 0.01, 10.0, 1.0)
                    model_sklearn = Lasso(alpha=alpha)
                    model_sklearn.fit(X_train, y_train)
                    y_pred = model_sklearn.predict(X_test)
                    
                    model_sm = sm.OLS(y_train, X_train_sm).fit()
                    residuals = y_train - model_sm.predict(X_train_sm)
                
                r2 = r2_score(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                mae = mean_absolute_error(y_test, y_pred)
                
                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                st.session_state.current_model = model_sm
                st.session_state.current_X_test = X_test
                st.session_state.current_y_test = y_test
                st.session_state.current_y_pred = y_pred
                
                st.markdown("---")
                st.markdown("## ğŸ“Š å›å¸°åˆ†æçµæœ")
                
                st.markdown("### ğŸ¯ ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®æ€§èƒ½")
                col_m1, col_m2, col_m3, col_m4 = st.columns(4)
                col_m1.metric("RÂ²", f"{r2:.4f}")
                col_m2.metric("èª¿æ•´æ¸ˆã¿RÂ²", f"{model_sm.rsquared_adj:.4f}")
                col_m3.metric("RMSE", f"{rmse:.4f}")
                col_m4.metric("MAE", f"{mae:.4f}")
                
                st.caption(f"Fçµ±è¨ˆé‡: {model_sm.fvalue:.2f}, på€¤: {model_sm.f_pvalue:.4e}")
                
                st.markdown("---")
                st.markdown("### ğŸ“ˆ å›å¸°ä¿‚æ•°ã®è©³ç´°")
                
                coef_df = pd.DataFrame({
                    'å¤‰æ•°': ['åˆ‡ç‰‡'] + selected_features,
                    'ä¿‚æ•°': model_sm.params.values,
                    'æ¨™æº–èª¤å·®': model_sm.bse.values,
                    'tå€¤': model_sm.tvalues.values,
                    'på€¤': model_sm.pvalues.values,
                    '95%CIä¸‹é™': model_sm.conf_int()[0].values,
                    '95%CIä¸Šé™': model_sm.conf_int()[1].values
                })
                
                coef_df['æœ‰æ„æ€§'] = coef_df['på€¤'].apply(
                    lambda x: '***' if x < 0.001 else '**' if x < 0.01 else '*' if x < 0.05 else 'n.s.'
                )
                
                coef_df_sorted = pd.concat([
                    coef_df[coef_df['å¤‰æ•°'] == 'åˆ‡ç‰‡'],
                    coef_df[coef_df['å¤‰æ•°'] != 'åˆ‡ç‰‡'].sort_values('ä¿‚æ•°', key=abs, ascending=False)
                ])
                
                st.dataframe(
                    coef_df_sorted.style.format({
                        'ä¿‚æ•°': '{:.4f}',
                        'æ¨™æº–èª¤å·®': '{:.4f}',
                        'tå€¤': '{:.3f}',
                        'på€¤': '{:.4f}',
                        '95%CIä¸‹é™': '{:.4f}',
                        '95%CIä¸Šé™': '{:.4f}'
                    }),
                    use_container_width=True
                )
                
                st.caption("æœ‰æ„æ°´æº–: *** p<0.001, ** p<0.01, * p<0.05, n.s. æœ‰æ„ã§ãªã„")
                
                st.markdown("#### ğŸ“Š ä¿‚æ•°ã®å¯è¦–åŒ–ï¼ˆä¿¡é ¼åŒºé–“ä»˜ãï¼‰")
                
                coef_plot_df = coef_df_sorted[coef_df_sorted['å¤‰æ•°'] != 'åˆ‡ç‰‡'].copy()
                
                fig_coef = go.Figure()
                
                colors = ['#e74c3c' if p < 0.05 else '#95a5a6' for p in coef_plot_df['på€¤']]
                fig_coef.add_trace(go.Bar(
                    y=coef_plot_df['å¤‰æ•°'],
                    x=coef_plot_df['ä¿‚æ•°'],
                    orientation='h',
                    marker=dict(color=colors),
                    error_x=dict(
                        type='data',
                        symmetric=False,
                        array=coef_plot_df['95%CIä¸Šé™'] - coef_plot_df['ä¿‚æ•°'],
                        arrayminus=coef_plot_df['ä¿‚æ•°'] - coef_plot_df['95%CIä¸‹é™']
                    ),
                    name='ä¿‚æ•°'
                ))
                
                fig_coef.add_vline(x=0, line_dash="dash", line_color="black", line_width=1)
                fig_coef.update_layout(
                    title="å›å¸°ä¿‚æ•°ã¨95%ä¿¡é ¼åŒºé–“ï¼ˆèµ¤=æœ‰æ„ã€ç°=éæœ‰æ„ï¼‰",
                    xaxis_title="ä¿‚æ•°ã®å€¤",
                    yaxis_title="å¤‰æ•°",
                    height=max(300, len(coef_plot_df) * 50),
                    showlegend=False
                )
                st.plotly_chart(fig_coef, use_container_width=True)
                
                st.markdown("#### ğŸ’¡ çµæœã®è§£é‡ˆ")
                st.info("""
                **ä¿‚æ•°ã®èª­ã¿æ–¹:**
                - **æ­£ã®ä¿‚æ•°**: ãã®å¤‰æ•°ãŒ1å˜ä½å¢—ãˆã‚‹ã¨ã€ç›®çš„å¤‰æ•°ãŒä¿‚æ•°åˆ†ã ã‘å¢—åŠ 
                - **è² ã®ä¿‚æ•°**: ãã®å¤‰æ•°ãŒ1å˜ä½å¢—ãˆã‚‹ã¨ã€ç›®çš„å¤‰æ•°ãŒä¿‚æ•°åˆ†ã ã‘æ¸›å°‘
                - **på€¤ < 0.05**: çµ±è¨ˆçš„ã«æœ‰æ„ï¼ˆå¶ç„¶ã§ã¯ãªã„å¯èƒ½æ€§ãŒé«˜ã„ï¼‰
                - **95%ä¿¡é ¼åŒºé–“**: çœŸã®ä¿‚æ•°ãŒå­˜åœ¨ã™ã‚‹ç¯„å›²ï¼ˆ95%ã®ç¢ºç‡ï¼‰
                """)
                
                significant_vars = coef_df_sorted[(coef_df_sorted['på€¤'] < 0.05) & (coef_df_sorted['å¤‰æ•°'] != 'åˆ‡ç‰‡')]
                if len(significant_vars) > 0:
                    st.success(f"âœ… **æœ‰æ„ãªå¤‰æ•°ï¼ˆp < 0.05ï¼‰**: {len(significant_vars)}å€‹")
                    for idx, row in significant_vars.iterrows():
                        direction = "å¢—åŠ " if row['ä¿‚æ•°'] > 0 else "æ¸›å°‘"
                        st.write(f"- **{row['å¤‰æ•°']}**: 1å˜ä½å¢—åŠ ã™ã‚‹ã¨ç›®çš„å¤‰æ•°ãŒ{abs(row['ä¿‚æ•°']):.4f}ã ã‘{direction} (p={row['på€¤']:.4f})")
                else:
                    st.warning("âš ï¸ çµ±è¨ˆçš„ã«æœ‰æ„ãªå¤‰æ•°ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
                diagnostics = comprehensive_regression_diagnostics(model_sm, X_train, y_train, residuals)
                display_diagnostics_report(diagnostics)
                
                effect_sizes = calculate_effect_sizes(model_sm, X_train, y_train)
                display_effect_sizes(effect_sizes)
                
                if enable_cv:
                    st.markdown("---")
                    with st.spinner("ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­..."):
                        model_for_cv = LinearRegression()
                        cv_results = rigorous_cross_validation(model_for_cv, X, y, cv=cv_folds)
                        
                        if cv_results:
                            display_cv_results(cv_results)
                
                st.markdown("---")
                st.markdown("### ğŸ¯ äºˆæ¸¬ç²¾åº¦ã®å¯è¦–åŒ–")
                
                col_plot1, col_plot2 = st.columns(2)
                
                with col_plot1:
                    fig_pred = go.Figure()
                    fig_pred.add_trace(go.Scatter(
                        x=y_test, y=y_pred,
                        mode='markers',
                        name='äºˆæ¸¬å€¤',
                        marker=dict(size=8, color='blue', opacity=0.6)
                    ))
                    fig_pred.add_trace(go.Scatter(
                        x=[y_test.min(), y_test.max()],
                        y=[y_test.min(), y_test.max()],
                        mode='lines',
                        name='ç†æƒ³ç·š',
                        line=dict(color='red', dash='dash')
                    ))
                    fig_pred.update_layout(
                        title="å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤",
                        xaxis_title="å®Ÿæ¸¬å€¤",
                        yaxis_title="äºˆæ¸¬å€¤"
                    )
                    st.plotly_chart(fig_pred, use_container_width=True)
                
                with col_plot2:
                    test_residuals = y_test - y_pred
                    fig_resid = px.scatter(x=y_pred, y=test_residuals, title="æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ")
                    fig_resid.add_hline(y=0, line_dash="dash", line_color="red")
                    fig_resid.update_xaxes(title="äºˆæ¸¬å€¤")
                    fig_resid.update_yaxes(title="æ®‹å·®")
                    st.plotly_chart(fig_resid, use_container_width=True)
                
                st.markdown("---")
                st.markdown("### ğŸ” å¤šé‡å…±ç·šæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆVIFï¼‰")
                vif_data = calculate_vif(regression_df, selected_features)
                if vif_data is not None:
                    st.dataframe(
                        vif_data.style.background_gradient(cmap='YlOrRd', subset=['VIF']),
                        use_container_width=True
                    )
                    st.caption("åŸºæº–: VIF < 5 (å•é¡Œãªã—), 5 < VIF < 10 (æ³¨æ„), VIF > 10 (æ·±åˆ»ãªå¤šé‡å…±ç·šæ€§)")
                    
                    if (vif_data['VIF'] > 10).any():
                        st.warning("âš ï¸ VIF > 10 ã®å¤‰æ•°ãŒã‚ã‚Šã¾ã™ã€‚Ridgeå›å¸°ã¾ãŸã¯Lassoå›å¸°ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
                
                with st.expander("ğŸ“‹ è©³ç´°ãªçµ±è¨ˆæƒ…å ±ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼‰"):
                    st.text(model_sm.summary())
                
                st.session_state.diagnostics_results = {
                    'model': model_sm,
                    'diagnostics': diagnostics,
                    'effect_sizes': effect_sizes,
                    'cv_results': cv_results if enable_cv else None,
                    'r2': r2,
                    'rmse': rmse,
                    'mae': mae
                }
                
                # ==================== ã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ©Ÿèƒ½ ====================
                st.markdown("---")
                st.markdown("### ğŸ’» ã“ã®åˆ†æã‚’å†ç¾ã™ã‚‹ã‚³ãƒ¼ãƒ‰")
                st.info("ä¸Šç´šè€…å‘ã‘ï¼šã“ã“ã¾ã§ã®åˆ†æã‚’å®Ÿè¡Œå¯èƒ½ãªPythonã‚³ãƒ¼ãƒ‰ã¨ã—ã¦å‡ºåŠ›ã—ã¾ã™")
                
                with st.expander("ğŸ“ Python ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", expanded=False):
                    generated_code = f'''"""
è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå›å¸°åˆ†æã‚³ãƒ¼ãƒ‰
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ç›®çš„å¤‰æ•°: {target}
èª¬æ˜å¤‰æ•°: {len(selected_features)}å€‹
ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {model_type}
"""

import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.diagnostic import het_breuschpagan, linear_rainbow
from statsmodels.stats.stattools import durbin_watson, jarque_bera
from sklearn.model_selection import train_test_split, cross_validate, KFold
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
import matplotlib.pyplot as plt
import seaborn as sns

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆâ€»ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰
df = pd.read_csv('your_data.csv')

print(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {{df.shape[0]}}è¡Œ Ã— {{df.shape[1]}}åˆ—")

# å‰å‡¦ç†ï¼ˆæ¬ æå€¤å‰Šé™¤ï¼‰
df_clean = df[['{target}'] + {selected_features}].dropna()
print(f"å‰å‡¦ç†å¾Œ: {{df_clean.shape[0]}}è¡Œ")

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X = df_clean{selected_features}
y = df_clean['{target}']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size={test_size}, 
    random_state=42
)

print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {{X_train.shape[0]}}è¡Œ")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {{X_test.shape[0]}}è¡Œ")

# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
'''
                    
                    if model_type == "é€šå¸¸ã®ç·šå½¢å›å¸°ï¼ˆOLSï¼‰":
                        generated_code += '''
# OLSå›å¸°ï¼ˆstatsmodelsï¼‰
X_train_sm = sm.add_constant(X_train)
X_test_sm = sm.add_constant(X_test)

model = sm.OLS(y_train, X_train_sm).fit()
y_pred = model.predict(X_test_sm)
'''
                    elif model_type == "Ridgeå›å¸°ï¼ˆæ­£å‰‡åŒ–ï¼‰":
                        generated_code += f'''
# Ridgeå›å¸°
model_sklearn = Ridge(alpha=1.0)
model_sklearn.fit(X_train, y_train)
y_pred = model_sklearn.predict(X_test)

# statsmodelsãƒ¢ãƒ‡ãƒ«ã‚‚ä½œæˆï¼ˆè¨ºæ–­ç”¨ï¼‰
X_train_sm = sm.add_constant(X_train)
model = sm.OLS(y_train, X_train_sm).fit()
'''
                    else:
                        generated_code += f'''
# Lassoå›å¸°
model_sklearn = Lasso(alpha=1.0)
model_sklearn.fit(X_train, y_train)
y_pred = model_sklearn.predict(X_test)

# statsmodelsãƒ¢ãƒ‡ãƒ«ã‚‚ä½œæˆï¼ˆè¨ºæ–­ç”¨ï¼‰
X_train_sm = sm.add_constant(X_train)
model = sm.OLS(y_train, X_train_sm).fit()
'''
                    
                    generated_code += f'''

# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)

print("\\n=== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ ===")
print(f"RÂ²: {{r2:.4f}}")
print(f"èª¿æ•´æ¸ˆã¿RÂ²: {{model.rsquared_adj:.4f}}")
print(f"RMSE: {{rmse:.4f}}")
print(f"MAE: {{mae:.4f}}")

# å›å¸°ä¿‚æ•°
print("\\n=== å›å¸°ä¿‚æ•° ===")
coef_df = pd.DataFrame({{
    'å¤‰æ•°': ['åˆ‡ç‰‡'] + list(X_train.columns),
    'ä¿‚æ•°': model.params.values,
    'på€¤': model.pvalues.values
}})
print(coef_df.to_string(index=False))

# çµ±è¨ˆçš„è¨ºæ–­
residuals = model.resid

# ç·šå½¢æ€§ï¼ˆRainbow Testï¼‰
try:
    rainbow_stat, rainbow_p = linear_rainbow(model)
    print(f"\\nç·šå½¢æ€§ï¼ˆRainbow Testï¼‰: p={{rainbow_p:.4f}}")
    if rainbow_p > 0.05:
        print("  âœ“ ç·šå½¢é–¢ä¿‚ãŒé©åˆ‡")
    else:
        print("  âœ— éç·šå½¢æ€§ã®å¯èƒ½æ€§ã‚ã‚Š")
except:
    print("\\nç·šå½¢æ€§æ¤œå®š: è¨ˆç®—ä¸å¯")

# ç­‰åˆ†æ•£æ€§ï¼ˆBreusch-Pagan Testï¼‰
try:
    X_train_sm = sm.add_constant(X_train)
    bp_stat, bp_p, _, _ = het_breuschpagan(residuals, X_train_sm)
    print(f"\\nç­‰åˆ†æ•£æ€§ï¼ˆBreusch-Paganï¼‰: p={{bp_p:.4f}}")
    if bp_p > 0.05:
        print("  âœ“ ç­‰åˆ†æ•£æ€§ã‚ã‚Š")
    else:
        print("  âœ— ä¸ç­‰åˆ†æ•£ï¼ˆWLSå›å¸°ã‚’æ¤œè¨ï¼‰")
except:
    print("\\nç­‰åˆ†æ•£æ€§æ¤œå®š: è¨ˆç®—ä¸å¯")

# æ­£è¦æ€§ï¼ˆJarque-Bera Testï¼‰
try:
    jb_stat, jb_p, skew, kurtosis = jarque_bera(residuals)
    print(f"\\næ­£è¦æ€§ï¼ˆJarque-Beraï¼‰: p={{jb_p:.4f}}")
    print(f"  æ­ªåº¦: {{skew:.4f}}, å°–åº¦: {{kurtosis:.4f}}")
    if jb_p > 0.05:
        print("  âœ“ æ­£è¦åˆ†å¸ƒã«å¾“ã†")
    else:
        print("  âœ— æ­£è¦æ€§é•å")
except:
    print("\\næ­£è¦æ€§æ¤œå®š: è¨ˆç®—ä¸å¯")

# è‡ªå·±ç›¸é–¢ï¼ˆDurbin-Watsonï¼‰
try:
    dw_stat = durbin_watson(residuals)
    print(f"\\nè‡ªå·±ç›¸é–¢ï¼ˆDurbin-Watsonï¼‰: {{dw_stat:.4f}}")
    if 1.5 < dw_stat < 2.5:
        print("  âœ“ è‡ªå·±ç›¸é–¢ãªã—")
    else:
        print("  âœ— è‡ªå·±ç›¸é–¢ã®å¯èƒ½æ€§")
except:
    print("\\nè‡ªå·±ç›¸é–¢æ¤œå®š: è¨ˆç®—ä¸å¯")

# å¤šé‡å…±ç·šæ€§ï¼ˆVIFï¼‰
try:
    vif_data = pd.DataFrame()
    vif_data["å¤‰æ•°"] = X_train.columns
    vif_data["VIF"] = [variance_inflation_factor(X_train.values, i) 
                       for i in range(len(X_train.columns))]
    
    print("\\n=== å¤šé‡å…±ç·šæ€§ï¼ˆVIFï¼‰ ===")
    print(vif_data.to_string(index=False))
    
    if (vif_data['VIF'] < 10).all():
        print("  âœ“ å¤šé‡å…±ç·šæ€§ãªã—ï¼ˆVIF<10ï¼‰")
    else:
        print("  âœ— å¤šé‡å…±ç·šæ€§ã‚ã‚Šï¼ˆRidge/Lassoå›å¸°ã‚’æ¤œè¨ï¼‰")
except:
    print("\\nå¤šé‡å…±ç·šæ€§è¨ˆç®—: è¨ˆç®—ä¸å¯")

# åŠ¹æœé‡ã®è¨ˆç®—
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)
X_scaled_df = pd.DataFrame(X_scaled, columns=X_train.columns)
X_scaled_with_const = sm.add_constant(X_scaled_df)
model_scaled = sm.OLS(y_train, X_scaled_with_const).fit()

beta_df = pd.DataFrame({{
    'å¤‰æ•°': X_train.columns,
    'æ¨™æº–åŒ–ä¿‚æ•°ï¼ˆBetaï¼‰': model_scaled.params[1:].values
}}).sort_values('æ¨™æº–åŒ–ä¿‚æ•°ï¼ˆBetaï¼‰', key=abs, ascending=False)

print("\\n=== æ¨™æº–åŒ–ä¿‚æ•°ï¼ˆåŠ¹æœã®å¤§ãã•ï¼‰===")
print(beta_df.to_string(index=False))

# Cohen's fÂ²
full_r2 = model.rsquared
if full_r2 < 1:
    cohens_f2 = full_r2 / (1 - full_r2)
    if cohens_f2 < 0.02:
        interpretation = "å°ã•ã„åŠ¹æœ"
    elif cohens_f2 < 0.15:
        interpretation = "ä¸­ç¨‹åº¦ã®åŠ¹æœ"
    elif cohens_f2 < 0.35:
        interpretation = "å¤§ãã„åŠ¹æœ"
    else:
        interpretation = "éå¸¸ã«å¤§ãã„åŠ¹æœ"
    
    print(f"\\nCohen's fÂ²: {{cohens_f2:.4f}} ({{interpretation}})")

# ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
print("\\n=== ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ ===")
cv_model = LinearRegression()
scoring = {{
    'r2': 'r2',
    'neg_mse': 'neg_mean_squared_error',
    'neg_mae': 'neg_mean_absolute_error'
}}

cv_results = cross_validate(
    cv_model, X, y,
    cv=KFold(n_splits={cv_folds}, shuffle=True, random_state=42),
    scoring=scoring,
    return_train_score=True,
    n_jobs=-1
)

train_r2 = cv_results['train_r2'].mean()
test_r2 = cv_results['test_r2'].mean()
overfit_gap = train_r2 - test_r2

print(f"è¨“ç·´RÂ²ï¼ˆå¹³å‡ï¼‰: {{train_r2:.4f}}")
print(f"ãƒ†ã‚¹ãƒˆRÂ²ï¼ˆå¹³å‡ï¼‰: {{test_r2:.4f}} Â± {{cv_results['test_r2'].std():.4f}}")
print(f"éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: {{overfit_gap:.4f}}")

if overfit_gap > 0.1:
    print("  âœ— éå­¦ç¿’ã®å…†å€™ã‚ã‚Šï¼ˆæ­£å‰‡åŒ–ã‚’æ¤œè¨ï¼‰")
else:
    print("  âœ“ éå­¦ç¿’ãªã—")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# äºˆæ¸¬vså®Ÿæ¸¬
axes[0, 0].scatter(y_test, y_pred, alpha=0.6)
axes[0, 0].plot([y_test.min(), y_test.max()], 
                [y_test.min(), y_test.max()], 
                'r--', lw=2)
axes[0, 0].set_xlabel('å®Ÿæ¸¬å€¤')
axes[0, 0].set_ylabel('äºˆæ¸¬å€¤')
axes[0, 0].set_title('å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤')

# æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
axes[0, 1].scatter(y_pred, y_test - y_pred, alpha=0.6)
axes[0, 1].axhline(y=0, color='r', linestyle='--')
axes[0, 1].set_xlabel('äºˆæ¸¬å€¤')
axes[0, 1].set_ylabel('æ®‹å·®')
axes[0, 1].set_title('æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ')

# æ®‹å·®ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
axes[1, 0].hist(residuals, bins=30, edgecolor='black')
axes[1, 0].set_xlabel('æ®‹å·®')
axes[1, 0].set_ylabel('é »åº¦')
axes[1, 0].set_title('æ®‹å·®ã®åˆ†å¸ƒ')

# Q-Qãƒ—ãƒ­ãƒƒãƒˆ
from scipy import stats as sp_stats
sp_stats.probplot(residuals, dist="norm", plot=axes[1, 1])
axes[1, 1].set_title('Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ­£è¦æ€§ç¢ºèªï¼‰')

plt.tight_layout()
plt.savefig('regression_diagnostics.png', dpi=300, bbox_inches='tight')
print("\\nå¯è¦–åŒ–ã‚’ 'regression_diagnostics.png' ã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸ")
plt.show()

# è©³ç´°ãªçµ±è¨ˆæƒ…å ±
print("\\n" + "="*60)
print("è©³ç´°ãªçµ±è¨ˆæƒ…å ±")
print("="*60)
print(model.summary())

# ã“ã“ã‹ã‚‰è‡ªç”±ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½
# ä¾‹ï¼š
# - äº¤äº’ä½œç”¨é …ã®è¿½åŠ : X['age_income'] = X['age'] * X['income']
# - éç·šå½¢é …: X['age_squared'] = X['age'] ** 2
# - ãƒ­ãƒã‚¹ãƒˆå›å¸°: from statsmodels.robust.robust_linear_model import RLM
# - WLSå›å¸°: sm.WLS(y, X, weights=...)
# - äºˆæ¸¬åŒºé–“: predictions.summary_frame(alpha=0.05)
'''
                    
                    st.code(generated_code, language='python')
                    
                    col_dl1, col_dl2, col_dl3 = st.columns(3)
                    
                    with col_dl1:
                        st.download_button(
                            "ğŸ’¾ .py ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜",
                            data=generated_code,
                            file_name=f"regression_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py",
                            mime="text/x-python",
                            type="primary"
                        )
                    
                    with col_dl2:
                        notebook_content = {
                            "cells": [
                                {
                                    "cell_type": "markdown",
                                    "metadata": {},
                                    "source": [
                                        f"# å›å¸°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n",
                                        f"**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n",
                                        f"**ç›®çš„å¤‰æ•°**: {target}\n",
                                        f"**èª¬æ˜å¤‰æ•°æ•°**: {len(selected_features)}å€‹\n",
                                        f"**ãƒ¢ãƒ‡ãƒ«**: {model_type}"
                                    ]
                                },
                                {
                                    "cell_type": "code",
                                    "execution_count": None,
                                    "metadata": {},
                                    "outputs": [],
                                    "source": generated_code.split('\n')
                                }
                            ],
                            "metadata": {
                                "kernelspec": {
                                    "display_name": "Python 3",
                                    "language": "python",
                                    "name": "python3"
                                },
                                "language_info": {
                                    "name": "python",
                                    "version": "3.8.0"
                                }
                            },
                            "nbformat": 4,
                            "nbformat_minor": 4
                        }
                        
                        notebook_json = json.dumps(notebook_content, indent=2)
                        
                        st.download_button(
                            "ğŸ““ Jupyter Notebook ã¨ã—ã¦ä¿å­˜",
                            data=notebook_json,
                            file_name=f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.ipynb",
                            mime="application/json",
                            type="primary"
                        )
                    
                    with col_dl3:
                        analysis_data = regression_df[[target] + selected_features]
                        csv_data = analysis_data.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            "ğŸ“Š åˆ†æãƒ‡ãƒ¼ã‚¿ï¼ˆCSVï¼‰ã‚’ä¿å­˜",
                            data=csv_data,
                            file_name=f"analysis_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                    
                    st.markdown("---")
                    st.success("""
                    âœ… **ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®ä½¿ã„æ–¹**:
                    1. `.py`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦Pythonç’°å¢ƒã§å®Ÿè¡Œ
                    2. Jupyter Notebookã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã
                    3. ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦è‡ªç”±ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
                    4. `your_data.csv`ã®éƒ¨åˆ†ã‚’å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«å¤‰æ›´
                    """)
                    
                    st.info("""
                    ğŸ’¡ **ä¸Šç´šè€…å‘ã‘ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºä¾‹**:
                    - äº¤äº’ä½œç”¨é …ã®è¿½åŠ : `X['age_income'] = X['age'] * X['income']`
                    - éç·šå½¢é …: `X['age_squared'] = X['age'] ** 2`
                    - ãƒ­ãƒã‚¹ãƒˆå›å¸°: `from statsmodels.robust.robust_linear_model import RLM`
                    - WLSå›å¸°ï¼ˆä¸ç­‰åˆ†æ•£å¯¾å¿œï¼‰: `sm.WLS(y, X, weights=...)`
                    - äºˆæ¸¬åŒºé–“ã®è¨ˆç®—: `predictions.summary_frame(alpha=0.05)`
                    """)
                
                st.success("âœ… å›å¸°åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
                
                # ==================== ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ====================
                               
                st.markdown("---")
                st.markdown("### ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆè‡ªå‹•å®Ÿè¡Œï¼‹å›å¸°å¯¾å¿œï¼‰")
                st.info("å›å¸°ãƒ¢ãƒ‡ãƒ«ã§ã‚‚äºˆæ¸¬å€¤ãŒé«˜ã„ï¼ãƒªã‚¹ã‚¯ãŒé«˜ã„ã¨è§£é‡ˆã—ã€é›¢è„±é˜²æ­¢æ–½ç­–ã®ROIã‚’Monte Carloã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§è¨ˆç®—ã—ã¾ã™")

                if (st.session_state.current_model is not None and 
                    st.session_state.current_y_pred is not None and 
                    st.session_state.current_X_test is not None and 
                    st.session_state.current_y_test is not None):

                    # å›å¸°ã®äºˆæ¸¬å€¤ã‚’0ï½1ã«æ­£è¦åŒ– â†’ ã€Œæ“¬ä¼¼é›¢è„±ç¢ºç‡ã€ã¨ã—ã¦ä½¿ç”¨
                    y_pred_raw = np.array(st.session_state.current_y_pred)
                    pred_proba_sim = (y_pred_raw - y_pred_raw.min()) / (y_pred_raw.max() - y_pred_raw.min() + 1e-12)

                    # ã“ã“ã§é–¢æ•°ã‚’ã€Œå‘¼ã³å‡ºã™ã ã‘ã€ã§ä¸­èº«ãŒå…¨éƒ¨è¡¨ç¤ºã•ã‚Œã‚‹ï¼ˆãƒœã‚¿ãƒ³ä¸è¦ã§å³è¡¨ç¤ºï¼‰
                    business_impact_simulation(
                        model=st.session_state.current_model,
                        X_test=st.session_state.current_X_test,
                        y_test=st.session_state.current_y_test,
                        y_pred=st.session_state.current_y_pred,
                        pred_proba=pred_proba_sim
                    )
                else:
                    st.warning("ãƒ¢ãƒ‡ãƒ«ãŒã¾ã å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã€Œå›å¸°åˆ†æå®Ÿè¡Œã€ã‚’å…ˆã«æŠ¼ã—ã¦ãã ã•ã„")
    
    # äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆæ©Ÿæ¢°å­¦ç¿’ï¼‰
    elif analysis_type == "ğŸ¯ äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆæ©Ÿæ¢°å­¦ç¿’ï¼‰":
        st.markdown("### æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹äºˆæ¸¬")
        
        selected_features = st.multiselect(
            "äºˆæ¸¬ã«ä½¿ç”¨ã™ã‚‹èª¬æ˜å¤‰æ•°",
            options=numeric_features,
            default=numeric_features[:min(10, len(numeric_features))]
        )
        
        if len(selected_features) == 0:
            st.warning("âš ï¸ èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
            st.stop()
        
        ml_df = df[[target] + selected_features].dropna()
        
        is_classification = len(ml_df[target].unique()) < 20 and not pd.api.types.is_float_dtype(ml_df[target])
        
        task_type = "åˆ†é¡" if is_classification else "å›å¸°"
        st.info(f"ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: **{task_type}** ï¼ˆç›®çš„å¤‰æ•°ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°: {ml_df[target].nunique()}ï¼‰")
        
        with st.expander("ğŸ”§ é«˜åº¦ãªè¨­å®š"):
            test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ", 0.1, 0.4, 0.2, 0.05)
            random_state = st.number_input("ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰", value=42, min_value=0)
            enable_cv = st.checkbox("ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ", value=True)
            cv_folds = st.slider("CVã®foldæ•°", 3, 10, 5) if enable_cv else 5
            if is_classification:
                ml_model = st.selectbox("ãƒ¢ãƒ‡ãƒ«é¸æŠ", ["ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆåˆ†é¡", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°"])
            else:
                ml_model = st.selectbox("ãƒ¢ãƒ‡ãƒ«é¸æŠ", ["ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°", "ç·šå½¢å›å¸°"])
        
        if st.button("âœ… ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Ÿè¡Œ", type="primary"):
            X = ml_df[selected_features]
            y = ml_df[target]
            
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
            
            with st.spinner("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­..."):
                if is_classification:
                    if ml_model == "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆåˆ†é¡":
                        model = RandomForestClassifier(n_estimators=100, random_state=random_state)
                    else:
                        model = LogisticRegression(max_iter=1000, random_state=random_state)
                else:
                    if ml_model == "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°":
                        model = RandomForestRegressor(n_estimators=100, random_state=random_state)
                    else:
                        model = LinearRegression()
                
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                
                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                st.session_state.current_model = model
                st.session_state.current_X_test = X_test
                st.session_state.current_y_test = y_test
                st.session_state.current_y_pred = y_pred
                
                st.markdown("---")
                st.markdown("## ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœ")
                
                if is_classification:
                    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
                    
                    st.markdown("### ãƒ¢ãƒ‡ãƒ«æ€§èƒ½")
                    
                    col_eval1, col_eval2, col_eval3, col_eval4 = st.columns(4)
                    col_eval1.metric("Precision", f"{precision_score(y_test, y_pred, average='weighted', zero_division=0):.3f}")
                    col_eval2.metric("Recall", f"{recall_score(y_test, y_pred, average='weighted', zero_division=0):.3f}")
                    col_eval3.metric("F1ã‚¹ã‚³ã‚¢", f"{f1_score(y_test, y_pred, average='weighted', zero_division=0):.3f}")
                    if y_pred_proba is not None and len(np.unique(y_test)) == 2:
                        col_eval4.metric("ROC-AUC", f"{roc_auc_score(y_test, y_pred_proba):.3f}")
                    
                    st.markdown("---")
                    st.markdown("#### æ··åŒè¡Œåˆ—")
                    cm = confusion_matrix(y_test, y_pred)
                    fig_cm = px.imshow(
                        cm,
                        text_auto=True,
                        title="æ··åŒè¡Œåˆ—",
                        labels=dict(x="äºˆæ¸¬", y="å®Ÿæ¸¬"),
                        color_continuous_scale='Blues'
                    )
                    st.plotly_chart(fig_cm, use_container_width=True)
                    
                    st.markdown("---")
                    st.markdown("#### è©³ç´°ãªåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ")
                    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
                    report_df = pd.DataFrame(report).transpose()
                    st.dataframe(report_df.style.format("{:.3f}"), use_container_width=True)
                    
                else:
                    r2 = r2_score(y_test, y_pred)
                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                    mae = mean_absolute_error(y_test, y_pred)
                    
                    col_eval1, col_eval2, col_eval3 = st.columns(3)
                    col_eval1.metric("RÂ² ã‚¹ã‚³ã‚¢", f"{r2:.4f}")
                    col_eval2.metric("RMSE", f"{rmse:.4f}")
                    col_eval3.metric("MAE", f"{mae:.4f}")
                    
                    st.markdown("---")
                    st.markdown("#### äºˆæ¸¬ vs å®Ÿæ¸¬")
                    fig_pred = px.scatter(x=y_test, y=y_pred, title="å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤",
                                         labels={'x': 'å®Ÿæ¸¬å€¤', 'y': 'äºˆæ¸¬å€¤'})
                    fig_pred.add_trace(go.Scatter(
                        x=[y_test.min(), y_test.max()],
                        y=[y_test.min(), y_test.max()],
                        mode='lines',
                        name='ç†æƒ³ç·š',
                        line=dict(color='red', dash='dash')
                    ))
                    st.plotly_chart(fig_pred, use_container_width=True)
                
                if enable_cv and not is_classification:
                    st.markdown("---")
                    with st.spinner("ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­..."):
                        cv_results = rigorous_cross_validation(model, X, y, cv=cv_folds)
                        
                        if cv_results:
                            display_cv_results(cv_results)
                
                st.markdown("---")
                st.markdown("### ğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦")
                
                if hasattr(model, 'feature_importances_'):
                    importance_df = pd.DataFrame({
                        'å¤‰æ•°': selected_features,
                        'é‡è¦åº¦': model.feature_importances_
                    }).sort_values('é‡è¦åº¦', ascending=False)
                    
                    fig_imp = px.bar(
                        importance_df.head(15),
                        x='é‡è¦åº¦',
                        y='å¤‰æ•°',
                        orientation='h',
                        title="ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆTop 15ï¼‰"
                    )
                    fig_imp.update_layout(height=max(400, len(importance_df.head(15)) * 30))
                    st.plotly_chart(fig_imp, use_container_width=True)
                    st.dataframe(importance_df, use_container_width=True)
                
                st.markdown("---")
                st.markdown("### ğŸ”„ Permutation Importance")
                
                try:
                    with st.spinner("Permutation Importanceè¨ˆç®—ä¸­..."):
                        perm_importance = permutation_importance(
                            model, X_test, y_test,
                            n_repeats=10,
                            random_state=random_state,
                            n_jobs=-1
                        )
                        
                        perm_df = pd.DataFrame({
                            'å¤‰æ•°': selected_features,
                            'é‡è¦åº¦': perm_importance.importances_mean,
                            'æ¨™æº–åå·®': perm_importance.importances_std
                        }).sort_values('é‡è¦åº¦', ascending=False)
                        
                        fig_perm = px.bar(
                            perm_df.head(15),
                            x='é‡è¦åº¦',
                            y='å¤‰æ•°',
                            error_x='æ¨™æº–åå·®',
                            orientation='h',
                            title="Permutation Importanceï¼ˆTop 15ï¼‰"
                        )
                        fig_perm.update_layout(height=max(400, len(perm_df.head(15)) * 30))
                        st.plotly_chart(fig_perm, use_container_width=True)
                        st.dataframe(perm_df, use_container_width=True)
                        
                except Exception as e:
                    st.warning(f"Permutation Importanceè¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼: {e}")
                
                st.markdown("---")
                st.markdown("### ğŸ’¡ ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ã‚µã‚¤ãƒˆ")
                
                if hasattr(model, 'feature_importances_'):
                    top_features = importance_df.head(3)['å¤‰æ•°'].tolist()
                    st.success(f"**æœ€é‡è¦å¤‰æ•°ï¼ˆTop 3ï¼‰**: {', '.join(top_features)}")
                    
                    st.info("""
                    **æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:**
                    - ä¸Šä½ã®é‡è¦å¤‰æ•°ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸæ–½ç­–ã‚’æ¤œè¨
                    - é‡è¦åº¦ã®ä½ã„å¤‰æ•°ã¯ç°¡ç•¥åŒ–ã‚’æ¤œè¨
                    - å®šæœŸçš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã—ã¦ç²¾åº¦ã‚’ç¶­æŒ
                    """)
                
                # ==================== æ©Ÿæ¢°å­¦ç¿’ç”¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ ====================
                st.markdown("---")
                st.markdown("### ğŸ’» ã“ã®äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å†ç¾ã™ã‚‹ã‚³ãƒ¼ãƒ‰")
                
                with st.expander("ğŸ“ Python ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", expanded=False):
                    task_label = "åˆ†é¡" if is_classification else "å›å¸°"
                    
                    ml_code = f'''"""
è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸæ©Ÿæ¢°å­¦ç¿’{task_label}ã‚³ãƒ¼ãƒ‰
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ã‚¿ã‚¹ã‚¯: {task_label}
ãƒ¢ãƒ‡ãƒ«: {ml_model}
èª¬æ˜å¤‰æ•°: {len(selected_features)}å€‹
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_validate, KFold
from sklearn.metrics import '''
                    
                    if is_classification:
                        ml_code += '''classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
'''
                    else:
                        ml_code += '''mean_squared_error, r2_score, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
'''
                    
                    ml_code += f'''from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt
import seaborn as sns

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = pd.read_csv('your_data.csv')

# æ¬ æå€¤å‰Šé™¤
df_clean = df[['{target}'] + {selected_features}].dropna()
print(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {{df_clean.shape[0]}}è¡Œ")

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X = df_clean{selected_features}
y = df_clean['{target}']

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size={test_size},
    random_state={random_state}
)

print(f"è¨“ç·´: {{X_train.shape[0]}}è¡Œ, ãƒ†ã‚¹ãƒˆ: {{X_test.shape[0]}}è¡Œ")

# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
'''
                    
                    if is_classification:
                        if ml_model == "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆåˆ†é¡":
                            ml_code += f'''
model = RandomForestClassifier(
    n_estimators=100,
    random_state={random_state},
    n_jobs=-1
)
'''
                        else:
                            ml_code += f'''
model = LogisticRegression(
    max_iter=1000,
    random_state={random_state},
    n_jobs=-1
)
'''
                    else:
                        if ml_model == "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°":
                            ml_code += f'''
model = RandomForestRegressor(
    n_estimators=100,
    random_state={random_state},
    n_jobs=-1
)
'''
                        else:
                            ml_code += '''
model = LinearRegression(n_jobs=-1)
'''
                    
                    ml_code += '''
# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
model.fit(X_train, y_train)

# äºˆæ¸¬
y_pred = model.predict(X_test)

# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
'''
                    
                    if is_classification:
                        ml_code += '''
from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

print("\\n=== åˆ†é¡æ€§èƒ½ ===")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1ã‚¹ã‚³ã‚¢: {f1:.4f}")

# æ··åŒè¡Œåˆ—
cm = confusion_matrix(y_test, y_pred)
print("\\næ··åŒè¡Œåˆ—:")
print(cm)

# è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
print("\\nè©³ç´°ãªåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
print(classification_report(y_test, y_pred, zero_division=0))

# ROC-AUCï¼ˆ2å€¤åˆ†é¡ã®å ´åˆï¼‰
if hasattr(model, 'predict_proba') and len(np.unique(y_test)) == 2:
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    print(f"\\nROC-AUC: {roc_auc:.4f}")
'''
                    else:
                        ml_code += '''
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)

print("\\n=== å›å¸°æ€§èƒ½ ===")
print(f"RÂ²ã‚¹ã‚³ã‚¢: {r2:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"MAE: {mae:.4f}")
'''
                    
                    ml_code += f'''
# ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
scoring = '''
                    
                    if is_classification:
                        ml_code += '''{'accuracy': 'accuracy', 'f1': 'f1_weighted'}
'''
                    else:
                        ml_code += '''{'r2': 'r2', 'neg_mse': 'neg_mean_squared_error'}
'''
                    
                    ml_code += f'''
cv_results = cross_validate(
    model, X, y,
    cv=KFold(n_splits={cv_folds if enable_cv else 5}, shuffle=True, random_state={random_state}),
    scoring=scoring,
    return_train_score=True,
    n_jobs=-1
)

print("\\n=== ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ ===")
'''
                    
                    if is_classification:
                        ml_code += '''
print(f"è¨“ç·´Accuracyï¼ˆå¹³å‡ï¼‰: {cv_results['train_accuracy'].mean():.4f}")
print(f"ãƒ†ã‚¹ãƒˆAccuracyï¼ˆå¹³å‡ï¼‰: {cv_results['test_accuracy'].mean():.4f} Â± {cv_results['test_accuracy'].std():.4f}")
'''
                    else:
                        ml_code += '''
print(f"è¨“ç·´RÂ²ï¼ˆå¹³å‡ï¼‰: {cv_results['train_r2'].mean():.4f}")
print(f"ãƒ†ã‚¹ãƒˆRÂ²ï¼ˆå¹³å‡ï¼‰: {cv_results['test_r2'].mean():.4f} Â± {cv_results['test_r2'].std():.4f}")

overfit_gap = cv_results['train_r2'].mean() - cv_results['test_r2'].mean()
if overfit_gap > 0.1:
    print("  âš ï¸ éå­¦ç¿’ã®å…†å€™ã‚ã‚Š")
else:
    print("  âœ“ éå­¦ç¿’ãªã—")
'''
                    
                    ml_code += '''
# ç‰¹å¾´é‡é‡è¦åº¦
if hasattr(model, 'feature_importances_'):
    importance_df = pd.DataFrame({
        'å¤‰æ•°': X.columns,
        'é‡è¦åº¦': model.feature_importances_
    }).sort_values('é‡è¦åº¦', ascending=False)
    
    print("\\n=== ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½10ï¼‰ ===")
    print(importance_df.head(10).to_string(index=False))
    
    # å¯è¦–åŒ–
    plt.figure(figsize=(10, 6))
    plt.barh(importance_df['å¤‰æ•°'].head(15), importance_df['é‡è¦åº¦'].head(15))
    plt.xlabel('é‡è¦åº¦')
    plt.title('ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆTop 15ï¼‰')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
    print("\\nç‰¹å¾´é‡é‡è¦åº¦ã‚’ 'feature_importance.png' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    plt.show()

# Permutation Importance
print("\\n=== Permutation Importanceï¼ˆè¨ˆç®—ä¸­...ï¼‰===")
perm_importance = permutation_importance(
    model, X_test, y_test,
    n_repeats=10,
    random_state=''' + str(random_state) + ''',
    n_jobs=-1
)

perm_df = pd.DataFrame({
    'å¤‰æ•°': X.columns,
    'é‡è¦åº¦': perm_importance.importances_mean,
    'æ¨™æº–åå·®': perm_importance.importances_std
}).sort_values('é‡è¦åº¦', ascending=False)

print("\\nPermutation Importanceï¼ˆä¸Šä½10ï¼‰:")
print(perm_df.head(10).to_string(index=False))

# äºˆæ¸¬çµæœã®å¯è¦–åŒ–
'''
                    
                    if not is_classification:
                        ml_code += '''
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# äºˆæ¸¬vså®Ÿæ¸¬
axes[0].scatter(y_test, y_pred, alpha=0.6)
axes[0].plot([y_test.min(), y_test.max()], 
             [y_test.min(), y_test.max()], 
             'r--', lw=2)
axes[0].set_xlabel('å®Ÿæ¸¬å€¤')
axes[0].set_ylabel('äºˆæ¸¬å€¤')
axes[0].set_title('å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤')

# æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
residuals = y_test - y_pred
axes[1].scatter(y_pred, residuals, alpha=0.6)
axes[1].axhline(y=0, color='r', linestyle='--')
axes[1].set_xlabel('äºˆæ¸¬å€¤')
axes[1].set_ylabel('æ®‹å·®')
axes[1].set_title('æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ')

plt.tight_layout()
plt.savefig('prediction_results.png', dpi=300, bbox_inches='tight')
print("\\näºˆæ¸¬çµæœã‚’ 'prediction_results.png' ã«ä¿å­˜ã—ã¾ã—ãŸ")
plt.show()
'''
                    else:
                        ml_code += '''
# æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('äºˆæ¸¬')
plt.ylabel('å®Ÿæ¸¬')
plt.title('æ··åŒè¡Œåˆ—')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
print("\\næ··åŒè¡Œåˆ—ã‚’ 'confusion_matrix.png' ã«ä¿å­˜ã—ã¾ã—ãŸ")
plt.show()
'''
                    
                    ml_code += '''
# ã“ã“ã‹ã‚‰è‡ªç”±ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½
# ä¾‹ï¼š
# - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆGridSearchCVï¼‰
# - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆVotingRegressor/Classifierï¼‰
# - SHAPå€¤ã«ã‚ˆã‚‹è§£é‡ˆæ€§å‘ä¸Š
# - æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
# - ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜: joblib.dump(model, 'model.pkl')
'''
                    
                    st.code(ml_code, language='python')
                    
                    col_ml1, col_ml2, col_ml3 = st.columns(3)
                    
                    with col_ml1:
                        st.download_button(
                            "ğŸ’¾ .py ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜",
                            data=ml_code,
                            file_name=f"ml_{task_label}_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py",
                            mime="text/x-python",
                            type="primary"
                        )
                    
                    with col_ml2:
                        notebook_ml = {
                            "cells": [
                                {
                                    "cell_type": "markdown",
                                    "metadata": {},
                                    "source": [
                                        f"# æ©Ÿæ¢°å­¦ç¿’{task_label}åˆ†æ\n",
                                        f"**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n",
                                        f"**ãƒ¢ãƒ‡ãƒ«**: {ml_model}\n",
                                        f"**èª¬æ˜å¤‰æ•°æ•°**: {len(selected_features)}å€‹"
                                    ]
                                },
                                {
                                    "cell_type": "code",
                                    "execution_count": None,
                                    "metadata": {},
                                    "outputs": [],
                                    "source": ml_code.split('\n')
                                }
                            ],
                            "metadata": {
                                "kernelspec": {
                                    "display_name": "Python 3",
                                    "language": "python",
                                    "name": "python3"
                                },
                                "language_info": {
                                    "name": "python",
                                    "version": "3.8.0"
                                }
                            },
                            "nbformat": 4,
                            "nbformat_minor": 4
                        }
                        
                        notebook_ml_json = json.dumps(notebook_ml, indent=2)
                        
                        st.download_button(
                            "ğŸ““ Jupyter Notebook ã¨ã—ã¦ä¿å­˜",
                            data=notebook_ml_json,
                            file_name=f"ml_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.ipynb",
                            mime="application/json",
                            type="primary"
                        )
                    
                    with col_ml3:
                        ml_analysis_data = ml_df[[target] + selected_features]
                        csv_ml_data = ml_analysis_data.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            "ğŸ“Š åˆ†æãƒ‡ãƒ¼ã‚¿ï¼ˆCSVï¼‰ã‚’ä¿å­˜",
                            data=csv_ml_data,
                            file_name=f"ml_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                    
                    st.success("""
                    âœ… **ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã§å¯èƒ½ãªã“ã¨**:
                    - ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ã¨äºˆæ¸¬
                    - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´
                    - æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
                    - ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿
                    """)
                    
                    st.info("""
                    ğŸ’¡ **ä¸Šç´šè€…å‘ã‘ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºä¾‹**:
                    - ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ: `GridSearchCV(model, param_grid, cv=5)`
                    - SHAPè§£é‡ˆ: `import shap; explainer = shap.TreeExplainer(model)`
                    - ãƒ¢ãƒ‡ãƒ«ä¿å­˜: `import joblib; joblib.dump(model, 'model.pkl')`
                    - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«: `VotingRegressor([('rf', rf), ('lr', lr)])`
                    """)
                
                st.success("âœ… äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
                
                # ==================== ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ====================
                st.markdown("---")
                st.markdown("### ğŸ’° ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
                
                # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
                if st.session_state.current_model is not None:
                    # äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—
                    pred_proba = None
                    if hasattr(st.session_state.current_model, "predict_proba"):
                        try:
                            pred_proba = st.session_state.current_model.predict_proba(st.session_state.current_X_test)[:, 1]
                        except:
                            pass
                    
                    # ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
                    business_impact_simulation(
                        st.session_state.current_model,
                        st.session_state.current_X_test,
                        st.session_state.current_y_test,
                        st.session_state.current_y_pred,
                        pred_proba
                    )
    
    # ==================== è‡ªå‹•æœ€é©åŒ–åˆ†æï¼ˆãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆçµ±åˆç‰ˆï¼‰ ====================
    elif analysis_type in ["ğŸš€ å›å¸°åˆ†æï¼ˆè‡ªå‹•æœ€é©åŒ–ï¼‰", "ğŸ¤– äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆè‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰"]:
        st.markdown("### ğŸ¤– è‡ªå‹•æœ€é©åŒ–åˆ†æ")
        
        st.info("ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã§æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•æ¢ç´¢ã—ã€ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™")
        
        selected_features = st.multiselect(
            "ä½¿ç”¨ã™ã‚‹èª¬æ˜å¤‰æ•°",
            options=numeric_features,
            default=numeric_features[:min(10, len(numeric_features))]
        )
        
        if len(selected_features) == 0:
            st.warning("âš ï¸ èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
            st.stop()
        
        auto_df = df[[target] + selected_features].dropna()
        
        is_classification = len(auto_df[target].unique()) < 20 and not pd.api.types.is_float_dtype(auto_df[target])
        
        task_type = "åˆ†é¡" if is_classification else "å›å¸°"
        st.info(f"ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: **{task_type}** ï¼ˆç›®çš„å¤‰æ•°ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°: {auto_df[target].nunique()}ï¼‰")
        
        with st.expander("ğŸ”§ é«˜åº¦ãªè¨­å®š"):
            test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ", 0.1, 0.4, 0.2, 0.05)
            random_state = st.number_input("ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰", value=42, min_value=0)
            cv_folds = st.slider("CVã®foldæ•°", 3, 10, 5)
        
        if st.button("ğŸš€ è‡ªå‹•æœ€é©åŒ–å®Ÿè¡Œ", type="primary"):
            X = auto_df[selected_features]
            y = auto_df[target]
            
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
            
            with st.spinner("ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–ä¸­..."):
                if is_classification:
                    # åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ
                    param_grid = {
                        'n_estimators': [50, 100, 200],
                        'max_depth': [3, 5, 7],
                        'min_samples_split': [2, 5, 10]
                    }
                    base_model = RandomForestClassifier(random_state=random_state)
                else:
                    # å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ
                    param_grid = {
                        'n_estimators': [50, 100, 200],
                        'max_depth': [3, 5, 7],
                        'min_samples_split': [2, 5, 10]
                    }
                    base_model = RandomForestRegressor(random_state=random_state)
                
                grid_search = GridSearchCV(
                    base_model, param_grid, 
                    cv=cv_folds, 
                    scoring='f1_weighted' if is_classification else 'r2',
                    n_jobs=-1,
                    verbose=1
                )
                
                grid_search.fit(X_train, y_train)
                
                best_model = grid_search.best_estimator_
                y_pred = best_model.predict(X_test)
                
                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                st.session_state.current_model = best_model
                st.session_state.current_X_test = X_test
                st.session_state.current_y_test = y_test
                st.session_state.current_y_pred = y_pred
                st.session_state.best_model = best_model
                
                st.markdown("---")
                st.markdown("## ğŸ† æœ€é©åŒ–çµæœ")
                
                st.success(f"**æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: {grid_search.best_params_}")
                st.success(f"**æœ€é©ã‚¹ã‚³ã‚¢**: {grid_search.best_score_:.4f}")
                
                if is_classification:
                    accuracy = (y_pred == y_test).mean()
                    st.metric("ãƒ†ã‚¹ãƒˆç²¾åº¦", f"{accuracy:.4f}")
                else:
                    r2 = r2_score(y_test, y_pred)
                    st.metric("ãƒ†ã‚¹ãƒˆRÂ²", f"{r2:.4f}")
                
                # ç‰¹å¾´é‡é‡è¦åº¦
                if hasattr(best_model, 'feature_importances_'):
                    st.markdown("---")
                    st.markdown("### ğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦")
                    
                    importance_df = pd.DataFrame({
                        'å¤‰æ•°': selected_features,
                        'é‡è¦åº¦': best_model.feature_importances_
                    }).sort_values('é‡è¦åº¦', ascending=False)
                    
                    fig_imp = px.bar(
                        importance_df.head(15),
                        x='é‡è¦åº¦',
                        y='å¤‰æ•°',
                        orientation='h',
                        title="æœ€é©ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆTop 15ï¼‰"
                    )
                    fig_imp.update_layout(height=max(400, len(importance_df.head(15)) * 30))
                    st.plotly_chart(fig_imp, use_container_width=True)
                
                # ==================== ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‘¼ã³å‡ºã— ====================
                st.markdown("---")
                st.markdown("### ğŸ’° ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
                
                # äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—
                pred_proba = None
                if hasattr(best_model, "predict_proba"):
                    try:
                        pred_proba = best_model.predict_proba(X_test)[:, 1]
                    except:
                        pass
                
                # ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
                business_impact_simulation(best_model, X_test, y_test, y_pred, pred_proba)
    
    st.markdown("---")
    if st.button("â¡ï¸ ã‚¹ãƒ†ãƒƒãƒ—5ã¸é€²ã‚€ï¼ˆè§£é‡ˆã¨ãƒ¬ãƒãƒ¼ãƒˆï¼‰", type="primary"):
        st.session_state.step = 5
        st.rerun()

# ã‚¹ãƒ†ãƒƒãƒ—5: è§£é‡ˆã¨ãƒ¬ãƒãƒ¼ãƒˆ
elif st.session_state.step == 5:
    st.markdown('<div class="step-header">5ï¸âƒ£ è§£é‡ˆã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ</div>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    <h4>ğŸ“Š åˆ†æçµæœã®è§£é‡ˆã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³</h4>
    <p>åˆ†æçµæœã‚’éå°‚é–€å®¶ã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ãè§£é‡ˆã—ã€å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆã—ã¾ã™</p>
    </div>
    """, unsafe_allow_html=True)
    
    report_title = st.text_input("ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ«", value="ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    report_summary = st.text_area(
        "åˆ†æã‚µãƒãƒªï¼ˆã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªï¼‰",
        height=150,
        placeholder="åˆ†æã®èƒŒæ™¯ã€ç›®çš„ã€ä¸»è¦ãªç™ºè¦‹ã‚’ç°¡æ½”ã«è¨˜è¿°ã—ã¦ãã ã•ã„...",
        key="report_summary"
    )
    
    st.markdown("---")
    
    st.subheader("ğŸ” ä¸»è¦ãªç™ºè¦‹")
    
    num_findings = st.number_input("ç™ºè¦‹ã®æ•°", min_value=1, max_value=10, value=3)
    findings = []
    for i in range(num_findings):
        finding = st.text_area(f"ç™ºè¦‹ {i+1}", key=f"finding_{i}",
                              placeholder="ä¾‹: å¤‰æ•°XãŒç›®çš„å¤‰æ•°ã«æœ€ã‚‚å¼·ã„æ­£ã®å½±éŸ¿ã‚’ä¸ãˆã¦ã„ã‚‹")
        findings.append(finding)
    
    st.markdown("---")
    
    st.subheader("ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    
    num_actions = st.number_input("ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ•°", min_value=1, max_value=10, value=3)
    actions = []
    for i in range(num_actions):
        action = st.text_area(f"ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ {i+1}", key=f"action_{i}",
                             placeholder="ä¾‹: å¤‰æ•°Xã®æ”¹å–„ã«æ³¨åŠ›ã™ã‚‹æ–½ç­–ã‚’å®Ÿæ–½ã™ã‚‹")
        actions.append(action)
    
    st.markdown("---")
    
    if st.button("ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰", type="primary"):
        st.markdown("---")
        st.markdown("## ğŸ“Š åˆ†æãƒ¬ãƒãƒ¼ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        
        report_content = f"""
# {report_title}

## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒª
{report_summary}

## åˆ†ææ¦‚è¦
- **åˆ†ææ—¥**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}
- **ãƒ‡ãƒ¼ã‚¿**: {st.session_state.df.shape[0]}è¡Œ Ã— {st.session_state.df.shape[1]}åˆ—
- **ç›®çš„å¤‰æ•°**: {st.session_state.selected_target}
- **èª¬æ˜å¤‰æ•°æ•°**: {len(st.session_state.selected_features)}å€‹

## ä¸»è¦ãªç™ºè¦‹

"""
        for i, finding in enumerate(findings, 1):
            if finding:
                report_content += f"{i}. {finding}\n\n"
        
        if st.session_state.diagnostics_results:
            report_content += """
## çµ±è¨ˆçš„å¦¥å½“æ€§ã®æ¤œè¨¼

"""
            diagnostics = st.session_state.diagnostics_results.get('diagnostics', {})
            
            passed_tests = [d.get('passed') for d in diagnostics.values() if d.get('passed') is not None]
            if passed_tests:
                pass_rate = sum(passed_tests) / len(passed_tests) * 100
                report_content += f"- **å‰ææ¡ä»¶ã®åˆæ ¼ç‡**: {pass_rate:.0f}%\n"
            
            for test_name, result in diagnostics.items():
                status = "âœ“ åˆæ ¼" if result.get('passed') else "âœ— ä¸åˆæ ¼"
                report_content += f"- **{result['test']}**: {status} - {result['interpretation']}\n"
            
            report_content += "\n"
            
            effect_sizes = st.session_state.diagnostics_results.get('effect_sizes', {})
            if effect_sizes.get('cohens_f2'):
                report_content += f"""
## åŠ¹æœé‡ï¼ˆå®Ÿå‹™çš„é‡è¦æ€§ï¼‰

- **Cohen's fÂ²**: {effect_sizes['cohens_f2']['value']:.4f} ({effect_sizes['cohens_f2']['interpretation']})

"""
        
        report_content += """
## æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

"""
        for i, action in enumerate(actions, 1):
            if action:
                report_content += f"{i}. {action}\n\n"
        
        report_content += """
## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
1. ææ¡ˆã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å„ªå…ˆé †ä½ä»˜ã‘
2. å®Ÿè¡Œè¨ˆç”»ã®ç­–å®šï¼ˆã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã€æ‹…å½“è€…ã€äºˆç®—ï¼‰
3. KPIè¨­å®šã¨åŠ¹æœæ¸¬å®šã®ä»•çµ„ã¿æ§‹ç¯‰
4. å®šæœŸçš„ãªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ã®ç¢ºç«‹

---
*æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯Data Science Workflow Studio Proã«ã‚ˆã‚Šç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
"""
        
        st.markdown(report_content)
        
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            md_bytes = report_content.encode('utf-8')
            st.download_button(
                "ğŸ“¥ Markdownãƒ¬ãƒãƒ¼ãƒˆ",
                data=md_bytes,
                file_name="analysis_report.md",
                mime="text/markdown"
            )
        
        with col2:
            if st.session_state.processed_df is not None:
                csv_bytes = st.session_state.processed_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "ğŸ“¥ å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ (CSV)",
                    data=csv_bytes,
                    file_name="processed_data.csv",
                    mime="text/csv"
                )
        
        with col3:
            html_content = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>{report_title}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 40px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        }}
        h1 {{
            color:#8b5cf6;
            border-bottom: 3px solid #8b5cf6;
            padding-bottom: 15px;
        }}
        h2 {{
            color: #6d28d9;
            margin-top: 30px;
        }}
        .meta-info {{
            background: #f3f4f6;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }}
        .finding {{
            background: #dbeafe;
            border-left: 4px solid #3b82f6;
            padding: 15px;
            margin: 15px 0;
            border-radius: 5px;
        }}
        .action {{
            background: #d1fae5;
            border-left: 4px solid #10b981;
            padding: 15px;
            margin: 15px 0;
            border-radius: 5px;
        }}
        .footer {{
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #e5e7eb;
            text-align: center;
            color: #6b7280;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>{report_title}</h1>
        
        <div class="meta-info">
            <p><strong>ç”Ÿæˆæ—¥æ™‚:</strong> {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}</p>
            <p><strong>ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º:</strong> {st.session_state.df.shape[0]}è¡Œ Ã— {st.session_state.df.shape[1]}åˆ—</p>
            <p><strong>ç›®çš„å¤‰æ•°:</strong> {st.session_state.selected_target}</p>
            <p><strong>èª¬æ˜å¤‰æ•°æ•°:</strong> {len(st.session_state.selected_features)}å€‹</p>
        </div>
        
        <h2>ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒª</h2>
        <p>{report_summary if report_summary else 'ï¼ˆè¨˜å…¥ãªã—ï¼‰'}</p>
        
        <h2>ä¸»è¦ãªç™ºè¦‹</h2>
"""
            
            for i, finding in enumerate(findings, 1):
                if finding:
                    html_content += f'<div class="finding"><strong>ç™ºè¦‹ {i}:</strong> {finding}</div>\n'
            
            if st.session_state.diagnostics_results:
                html_content += """
        <h2>çµ±è¨ˆçš„å¦¥å½“æ€§ã®æ¤œè¨¼</h2>
"""
                diagnostics = st.session_state.diagnostics_results.get('diagnostics', {})
                
                for test_name, result in diagnostics.items():
                    status = "âœ“ åˆæ ¼" if result.get('passed') else "âœ— ä¸åˆæ ¼"
                    html_content += f'<p><strong>{status}</strong> {result["test"]}: {result["interpretation"]}</p>\n'
                
                effect_sizes = st.session_state.diagnostics_results.get('effect_sizes', {})
                if effect_sizes.get('cohens_f2'):
                    html_content += f"""
        <h2>åŠ¹æœé‡ï¼ˆå®Ÿå‹™çš„é‡è¦æ€§ï¼‰</h2>
        <p><strong>Cohen's fÂ²:</strong> {effect_sizes['cohens_f2']['value']:.4f} ({effect_sizes['cohens_f2']['interpretation']})</p>
"""
            
            html_content += """
        <h2>æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³</h2>
"""
            
            for i, action in enumerate(actions, 1):
                if action:
                    html_content += f'<div class="action"><strong>ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ {i}:</strong> {action}</div>\n'
            
            html_content += f"""
        <div class="footer">
            <p><strong>æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯Data Science Workflow Studio Proã«ã‚ˆã‚Šç”Ÿæˆã•ã‚Œã¾ã—ãŸ</strong></p>
        </div>
    </div>
</body>
</html>
"""
            
            html_bytes = html_content.encode('utf-8')
            st.download_button(
                "ğŸ“¥ HTMLãƒ¬ãƒãƒ¼ãƒˆ",
                data=html_bytes,
                file_name=f"{report_title.replace(' ', '_')}_report.html",
                mime="text/html"
            )
    
    st.markdown("---")
    st.markdown("""
    <div class="success-box">
    <h3>åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ</h3>
    <p>ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’é–¢ä¿‚è€…ã¨å…±æœ‰ã—ã€æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å®Ÿè£…ã‚’æ¤œè¨ã—ã¦ãã ã•ã„</p>
    </div>
    """, unsafe_allow_html=True)
    
    col_final1, col_final2, col_final3 = st.columns(3)
    
    with col_final1:
        if st.button("ğŸ”„ æ–°ã—ã„åˆ†æã‚’é–‹å§‹", type="secondary"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.session_state.step = 1
            st.rerun()
    
    with col_final2:
        if st.button("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—4ã«æˆ»ã‚‹ï¼ˆè¿½åŠ åˆ†æï¼‰", type="secondary"):
            st.session_state.step = 4
            st.rerun()
    
    with col_final3:
        if st.button("ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—3ã«æˆ»ã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿å†å‡¦ç†ï¼‰", type="secondary"):
            st.session_state.step = 3
            st.rerun()

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #64748b; padding: 2rem;">
    <p><strong>Data Science Workflow Studio Pro</strong></p>
    <p>çµ±è¨ˆã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã®å³å¯†æ€§ + ã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ©Ÿèƒ½ + ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æ</p>
</div>
""", unsafe_allow_html=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ˜ãƒ«ãƒ—æƒ…å ±
with st.sidebar:
    st.markdown("---")
    st.markdown("### ğŸ’¡ ãƒ˜ãƒ«ãƒ—")
    
    with st.expander("ä½¿ã„æ–¹ã®ãƒ’ãƒ³ãƒˆ"):
        st.markdown("""
        **ã‚¹ãƒ†ãƒƒãƒ—1: å•é¡Œå®šç¾©**
        - ä½•ã®ãŸã‚ã®åˆ†æã‹æ˜ç¢ºã«
        
        **ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿ç†è§£**
        - å¤‰æ•°åã‚’ã‚ã‹ã‚Šã‚„ã™ãç·¨é›†
        - ç›®çš„å¤‰æ•°ã¨èª¬æ˜å¤‰æ•°ã‚’é¸æŠ
        
        **ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†**
        - æ¬ æå€¤ãƒ»å¤–ã‚Œå€¤ã‚’å‡¦ç†
        - å¿…è¦ãªå¤‰æ›ã‚’é©ç”¨
        
        **ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒªãƒ³ã‚°**
        - çµ±è¨ˆçš„å‰ææ¡ä»¶ã‚’è‡ªå‹•æ¤œè¨¼
        - åŠ¹æœé‡ã§å®Ÿå‹™çš„é‡è¦æ€§ã‚’è©•ä¾¡
        - **ã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ©Ÿèƒ½ã§è‡ªç”±ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º**
        - **ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**
        
        **ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¬ãƒãƒ¼ãƒˆ**
        - ç™ºè¦‹ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¨˜è¼‰
        """)
    
    with st.expander("ã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ©Ÿèƒ½ã«ã¤ã„ã¦"):
        st.markdown("""
        **å„åˆ†æã§å®Ÿè¡Œå¯èƒ½ãªPythonã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ:**
        
        1. **.pyãƒ•ã‚¡ã‚¤ãƒ«**: ãã®ã¾ã¾å®Ÿè¡Œå¯èƒ½
        2. **Jupyterãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯**: ãƒ–ãƒ©ã‚¦ã‚¶ã§ç·¨é›†ãƒ»å®Ÿè¡Œ
        3. **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºè‡ªç”±**: äº¤äº’ä½œç”¨é …ã€éç·šå½¢é …ã€ãƒ­ãƒã‚¹ãƒˆå›å¸°ãªã©ã‚’è¿½åŠ å¯èƒ½
        
        **ä¸Šç´šè€…ã®ä½¿ã„æ–¹:**
        - ã‚¢ãƒ—ãƒªã§åŸºæœ¬åˆ†æã‚’å®Ÿæ–½
        - ã‚³ãƒ¼ãƒ‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        - è‡ªåˆ†ã®ç’°å¢ƒã§é«˜åº¦ãªåˆ†æã«æ‹¡å¼µ
        - GridSearchCVã€SHAPã€å› æœæ¨è«–ãªã©
        """)
    
    with st.expander("ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æ"):
        st.markdown("""
        **Monte Carloã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:**
        
        - ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸROIè¨ˆç®—
        - 95%ä¿¡é ¼åŒºé–“ã§ã®åˆ©ç›Šäºˆæ¸¬
        - ä»‹å…¥æˆ¦ç•¥ã®æœ€é©åŒ–
        
        **å®Ÿå‹™æ´»ç”¨ä¾‹:**
        - é¡§å®¢é›¢è„±é˜²æ­¢æ–½ç­–ã®åŠ¹æœäºˆæ¸¬
        - ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®ROIè¨ˆç®—
        - ãƒªã‚¹ã‚¯ç®¡ç†ã®å®šé‡åŒ–
        """)
    
    with st.expander("çµ±è¨ˆçš„å³å¯†æ€§ã«ã¤ã„ã¦"):
        st.markdown("""
        **æœ¬ã‚¢ãƒ—ãƒªã®çµ±è¨ˆçš„æ¤œè¨¼:**
        
        1. **å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯**
           - ç·šå½¢æ€§ï¼ˆRainbow Testï¼‰
           - ç­‰åˆ†æ•£æ€§ï¼ˆBreusch-Paganï¼‰
           - æ­£è¦æ€§ï¼ˆJarque-Beraï¼‰
           - è‡ªå·±ç›¸é–¢ï¼ˆDurbin-Watsonï¼‰
           - å¤šé‡å…±ç·šæ€§ï¼ˆVIFï¼‰
        
        2. **åŠ¹æœé‡ã®è¨ˆç®—**
           - Cohen's fÂ²
           - æ¨™æº–åŒ–ä¿‚æ•°ï¼ˆBetaï¼‰
           - Partial RÂ²
        
        3. **éå­¦ç¿’ã®æ¤œè¨¼**
           - K-fold ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        """)
    
    with st.expander("çµ±è¨ˆç”¨èªé›†"):
        st.markdown("""
        **RÂ²ï¼ˆæ±ºå®šä¿‚æ•°ï¼‰**: ãƒ¢ãƒ‡ãƒ«ã®å½“ã¦ã¯ã¾ã‚Šï¼ˆ0-1ï¼‰
        
        **RMSE**: äºˆæ¸¬èª¤å·®ã®å¤§ãã•
        
        **på€¤**: çµ±è¨ˆçš„æœ‰æ„æ€§ï¼ˆ< 0.05ã§æœ‰æ„ï¼‰
        
        **VIF**: å¤šé‡å…±ç·šæ€§ï¼ˆ> 10ã§å•é¡Œï¼‰
        
        **Cohen's fÂ²**: åŠ¹æœã®å¤§ãã•
        - å°: 0.02, ä¸­: 0.15, å¤§: 0.35
        """)


